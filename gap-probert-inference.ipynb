{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "# !pip install torch\n",
    "# !pip install transformers==4.34.0\n",
    "# !pip install pycorenlp==0.3.0\n",
    "# !pip install python-dotenv==1.0.0\n",
    "# !pip install pytorch-pretrained-bert==0.6.2\n",
    "# !pip install pandas==2.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub.hf_api import HfFolder \n",
    "import os, json, re, contextlib\n",
    "# import AttrDict\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch.utils.data import DataLoader, SequentialSampler,TensorDataset\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from pickle import FALSE, TRUE\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "class AttrDict(dict):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# private hf model token needed. give write persmission if push to hub is expected\n",
    "# save in .env file with HF_TOKEN key\n",
    "# see https://huggingface.co/docs/transformers.js/guides/private\n",
    "HfFolder.save_token(os.environ.get(\"HF_TOKEN\"))\n",
    "os.environ['TRANSFORMERS_CACHE'] = './cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProBERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not False else \"cpu\")\n",
    "# Load tokenizer and model directly from hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ibm/probert\", use_auth_token=True, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"ibm/probert\", use_auth_token=True, trust_remote_code=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Entities and Pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Any library can be used to extract the entities and pronouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pronouns = ['she', 'her', 'hers', 'he', 'him', 'his']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_corenlp_url = 'https://corenlp.run/'\n",
    "corenlp = StanfordCoreNLP(_corenlp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pronoun(sentence, entity):\n",
    "    for token_dict in sentence['tokens']:\n",
    "        if token_dict['originalText'] == entity:\n",
    "            return token_dict['pos'] == 'PRP' or token_dict['pos'] == 'PRP$'\n",
    "\n",
    "# need to get combinations of every pronoun + offset with every entity + offset\n",
    "def get_combinations(entity_dict, pronoun_dict):\n",
    "    combinations = []\n",
    "    # each pronoun\n",
    "    for pronoun in pronoun_dict:\n",
    "        # offset for each pronoun\n",
    "        for pronoun_offset in pronoun_dict[pronoun]:\n",
    "            finished_entities = []\n",
    "            # each pair of entities\n",
    "            for entity1 in entity_dict:\n",
    "                # no duplicates (only want one of [[entity1 = a], [entity2 = b]])\n",
    "                if entity1 not in finished_entities:\n",
    "                    # offset for each entity\n",
    "                    for entity1_offset in entity_dict[entity1]:\n",
    "                        combinations.append([pronoun, pronoun_offset, entity1, entity1_offset])\n",
    "                finished_entities.append(entity1)\n",
    "            \n",
    "    return combinations\n",
    "\n",
    "def get_entities_and_pronouns(original_text: List[str]):\n",
    "    entity_list, pronoun_list = [], []\n",
    "    if type(original_text) != list and original_text != []:\n",
    "        raise Exception(\"Input must be a list of strings.\")\n",
    "    \n",
    "    for i in range(len(original_text)):\n",
    "        entity_dict, pronoun_dict = {}, {}\n",
    "        root = json.loads(corenlp.annotate(original_text[i], properties={'annotators': 'parse,coref,openie,ner', \"timeout\": \"50000\"}))\n",
    "\n",
    "        for sentence_idx in range(len(root['sentences'])):\n",
    "            sentence = root['sentences'][sentence_idx]\n",
    "            for idx in range(len(sentence['entitymentions'])):\n",
    "                entity = sentence['entitymentions'][idx]['ner']\n",
    "                text = sentence['entitymentions'][idx]['text']\n",
    "                if entity == 'PERSON' or entity == 'TITLE':\n",
    "                    if not is_pronoun(sentence, text):\n",
    "                        entity_dict[text] = []\n",
    "            for token_dict in sentence['tokens']:\n",
    "                if token_dict['pos'] == 'PRP' or token_dict['pos'] == 'PRP$':\n",
    "                    pronoun_dict[token_dict['originalText']] = []\n",
    "        # add offset from ORIGINAL text \n",
    "        # (can't add directly from above because coref annotation adds spaces / other chars) \n",
    "        for name in entity_dict:\n",
    "            if entity_dict[name] == []:\n",
    "                entity_dict[name] = [word.start() for word in re.finditer(name, original_text[i])]\n",
    "        for name in pronoun_dict:\n",
    "            if pronoun_dict[name] == []:\n",
    "                regex=re.compile(rf\"\\b{name}\\b\")\n",
    "                pronoun_dict[name] = [word.start() for word in regex.finditer(original_text[i])]\n",
    "        \n",
    "        entity_list.append(entity_dict)\n",
    "        pronoun_list.append(pronoun_dict)\n",
    "    return entity_list, pronoun_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data by annotating with new mention and pronoun tags.\n",
    "def annotate_mentions(ex):\n",
    "        ex.a_offset = int(ex.a_offset)\n",
    "        ex.pronoun_offset = int(ex.pronoun_offset)\n",
    "        text = ex.text\n",
    "        \n",
    "        text = '{}<A> {}'.format(text[:ex.a_offset], text[ex.a_offset:])\n",
    "        offset = ex.pronoun_offset\n",
    "        if ex.pronoun_offset > ex.a_offset:\n",
    "            offset += 4\n",
    "            \n",
    "        text = '{}<P> {}'.format(text[:offset], text[offset:])\n",
    "        ex.a_offset = text.index('<A> ') + 4\n",
    "        ex.pronoun_offset = text.index('<P> ') + 4\n",
    "        offset = 5*len(re.findall('<(C|D|E)_.>', re.search(''.join([re.escape(c)+'(<(C|D|E)_.>)*?' for c in ex.a]), text[ex.a_offset:])[0]))\n",
    "        text = '{} <A>{}'.format(text[:ex.a_offset+len(ex.a)+offset], text[ex.a_offset+len(ex.a)+offset:])\n",
    "        \n",
    "        offset = 0\n",
    "        if ex.pronoun_offset > ex.a_offset:\n",
    "            offset += 4\n",
    "        offset += 5*len(re.findall('<(C|D|E)_.>', text[ex.pronoun_offset:ex.pronoun_offset+len(ex.pronoun)]))\n",
    "        text = '{} <P>{}'.format(text[:ex.pronoun_offset+len(ex.pronoun)+offset], \n",
    "                                    text[ex.pronoun_offset+len(ex.pronoun)+offset:])\n",
    "\n",
    "        ex.text = text \n",
    "        return text\n",
    "\n",
    "\n",
    "def transform(X, pretrained=None):\n",
    "    # X = pd.read_csv(X, sep='\\t')\n",
    "    X = X.copy()\n",
    "    X['text'] = X.progress_apply(annotate_mentions, axis=1)\n",
    "    pretrained = pd.DataFrame(np.ones((len(X), 2))*0.33)\n",
    "    y = pd.DataFrame([[False]]*len(X), columns=['A'])\n",
    "    y['NEITHER'] = ~y['A']\n",
    "    if 'a_coref' in X.columns:\n",
    "        y = pd.DataFrame(X[['a_coref']].values, columns=['A'])\n",
    "        y['NEITHER'] = ~y['A']\n",
    "            \n",
    "    X['label'] = np.argmax(y.values, axis=1)\n",
    "    X['pretrained'] = pretrained.values.tolist()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Convert to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, \n",
    "                                    tokenizer,\n",
    "                                    max_seq_length,\n",
    "                                    n_coref_models,\n",
    "                                    max_gpr_mention_len=20,\n",
    "                                    pad_value=0,\n",
    "                                    verbose=0):\n",
    "\n",
    "    features = []\n",
    "    for ex_index, example in tqdm(examples.iterrows(), \n",
    "                                    desc='Convert Examples to features', \n",
    "                                    disable=False):\n",
    "\n",
    "        tokens = tokenizer.tokenize(example.text)\n",
    "\n",
    "        if get_sanitized_seq_len(tokens)[0] > max_seq_length - 2:\n",
    "            tokens = _truncate_seq(tokens, max_seq_length - 2)\n",
    "\n",
    "        tokens_ = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "\n",
    "        # first set with gpr tags\n",
    "        tokens, _, _, _ = extract_cluster_ids(ex_index,\n",
    "                                           tokens_.copy(),\n",
    "                                           n_coref_models,\n",
    "                                           max_mention_len=8,\n",
    "                                           remove_gpr_tags=False)\n",
    "\n",
    "        # second without gpr tags only to be used for coref clusters embeddings\n",
    "        _, cluster_ids_a, cluster_ids_b, cluster_ids_p = extract_cluster_ids(ex_index, \n",
    "                                                                            tokens_.copy(), \n",
    "                                                                            n_coref_models, \n",
    "                                                                            max_mention_len=8,\n",
    "                                                                            remove_gpr_tags=True)\n",
    "        \n",
    "        # mention_ids = A, B and P entity token indices\n",
    "        # gpr_tag_ids = <A>, <B>, <P> tag token indices\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. \n",
    "        mention_p_ids, mention_a_ids, mention_b_ids, gpr_tag_ids = get_gpr_mention_ids(tokens, \n",
    "                                                                                        max_gpr_mention_len,\n",
    "                                                                                        ignore_gpr_tags=True)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        gpr_tags_mask = np.zeros(len(tokens))\n",
    "        gpr_tags_mask[gpr_tag_ids] = 1\n",
    "        gpr_tags_mask = gpr_tags_mask.tolist()\n",
    "        mention_p_mask = [1] * len(mention_p_ids)\n",
    "        mention_a_mask = [1] * len(mention_a_ids)\n",
    "\n",
    "        # Zero-pad up to the max sequence length.\n",
    "        padding = [pad_value] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        gpr_tags_mask += padding\n",
    "        mention_p_ids += [pad_value] * (max_gpr_mention_len - len(mention_p_ids))\n",
    "        mention_a_ids += [pad_value] * (max_gpr_mention_len - len(mention_a_ids))\n",
    "        mention_p_mask += [pad_value] * (max_gpr_mention_len - len(mention_p_mask))\n",
    "        mention_a_mask += [pad_value] * (max_gpr_mention_len - len(mention_a_mask))\n",
    "\n",
    "        # Zero pad coref clusters\n",
    "        cluster_ids_a, cluster_mask_a = pad_cluster_ids(cluster_ids_a, n_coref_models, \n",
    "                                                        max_seq_length,\n",
    "                                                        max_mention_len=8,\n",
    "                                                        max_coref_mentions=20,\n",
    "                                                        pad_value=pad_value)\n",
    "        cluster_ids_p, cluster_mask_p = pad_cluster_ids(cluster_ids_p, n_coref_models, \n",
    "                                                        max_seq_length,\n",
    "                                                        max_mention_len=8,\n",
    "                                                        max_coref_mentions=20,\n",
    "                                                        pad_value=pad_value)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(tokens) <= max_seq_length, '{}\\n{}\\n{}'.format(ex_index, len(tokens), tokens)\n",
    "        assert ''.join(tokens).upper().count('<P>') == 2 and ''.join(tokens).upper().count('<A>') == 2, (ex_index,\n",
    "        \"\".join(tokens).upper().count('<P>'), \"\".join(tokens).upper().count('<A>'),\"\".join(tokens))\n",
    "\n",
    "        features.append(\n",
    "                AttrDict({'input_ids': input_ids,\n",
    "                              'input_mask': input_mask,\n",
    "                              'segment_ids': segment_ids,\n",
    "                              'gpr_tags_mask': gpr_tags_mask,\n",
    "                              'mention_p_ids': mention_p_ids,\n",
    "                              'mention_a_ids': mention_a_ids,\n",
    "                              'mention_p_mask': mention_p_mask,\n",
    "                              'mention_a_mask': mention_a_mask,\n",
    "                              'cluster_ids_a': cluster_ids_a,\n",
    "                              'cluster_mask_a': cluster_mask_a,\n",
    "                              'cluster_ids_p': cluster_ids_p,\n",
    "                              'cluster_mask_p': cluster_mask_p,\n",
    "                              'label_id': example.label,\n",
    "                              'pretrained': example.pretrained}))\n",
    "    return features\n",
    "\n",
    "def get_gpr_mention_ids(tokens, max_gpr_mention_len, ignore_gpr_tags=False):\n",
    "    gpr_ids = {'<P>': [], '<A>': [], '<B>': []}\n",
    "    gpr_tag_ids = []\n",
    "    entity = None\n",
    "    for i, token_ in enumerate(tokens):\n",
    "        token = ''.join(tokens[i:i+3]).upper()\n",
    "\n",
    "        if token in ['<P>', '<A>', '<B>']:\n",
    "            gpr_tag_ids += [i, i+1, i+2]\n",
    "            gpr_tag_ids_now = [i, i+1, i+2]\n",
    "\n",
    "        if entity is not None and token not in ['<P>', '<A>', '<B>']:\n",
    "            if ignore_gpr_tags:\n",
    "                gpr_ids[entity].append(i+2-len(gpr_tag_ids_now))\n",
    "            else:\n",
    "                gpr_ids[entity].append(i+2)\n",
    "\n",
    "        if token in ['<P>', '<A>', '<B>']:\n",
    "            if entity == token:\n",
    "                entity = None\n",
    "            else:\n",
    "                entity = token\n",
    "    # This is only returning 1 mention id for <P> and 2 for <A>. Think there's a bug here.\n",
    "    return (gpr_ids['<P>'][:][:max_gpr_mention_len], \n",
    "            # gpr_ids['<P>'][:-2][:max_gpr_mention_len], \n",
    "            gpr_ids['<A>'][:-2][:max_gpr_mention_len], \n",
    "            gpr_ids['<B>'][:-2][:max_gpr_mention_len], \n",
    "            gpr_tag_ids)\n",
    "\n",
    "def pad_cluster_ids(cluster_ids, n_coref_models, max_seq_length, \n",
    "                    max_mention_len=4, \n",
    "                    max_coref_mentions=5,\n",
    "                    pad_value=0):\n",
    "    # pad cluster ids\n",
    "    cluster_mask = [[] for i in range(n_coref_models)]\n",
    "\n",
    "    for model_idx in range(n_coref_models):\n",
    "        # limit to 10 mentions max for now\n",
    "        # pad mentions length\n",
    "        model_cluster_ids = cluster_ids[model_idx][:max_coref_mentions]\n",
    "        for i, mention in enumerate(model_cluster_ids):\n",
    "            cluster_mask[model_idx].append([1] * len(model_cluster_ids[i]) + [0] * (max_mention_len-len(model_cluster_ids[i])))\n",
    "            model_cluster_ids[i] += [pad_value] * (max_mention_len-len(model_cluster_ids[i]))\n",
    "        cluster_ids[model_idx] = model_cluster_ids\n",
    "\n",
    "        # pad cluster lengths\n",
    "        if len(cluster_ids[model_idx]) < max_coref_mentions:\n",
    "            cluster_ids[model_idx] += [[pad_value] * max_mention_len] * (max_coref_mentions-len(cluster_ids[model_idx]))\n",
    "            cluster_mask[model_idx] += [[0] * max_mention_len] * (max_coref_mentions-len(cluster_mask[model_idx]))\n",
    "\n",
    "    return cluster_ids, cluster_mask\n",
    "\n",
    "def populate_cluster(cluster_ids, tokens_to_remove, token_ids):\n",
    "    if len(cluster_ids[-1]) == 0:\n",
    "        tokens_to_remove += token_ids\n",
    "        cluster_ids[-1].append(token_ids[-1] + 1 - len(tokens_to_remove))\n",
    "    else:\n",
    "        mention_tokens = range(cluster_ids[-1][0], token_ids[0] - len(tokens_to_remove))\n",
    "        mention_tokens = list(mention_tokens)\n",
    "        cluster_ids.pop()\n",
    "        cluster_ids.append(mention_tokens)\n",
    "        tokens_to_remove += token_ids\n",
    "        cluster_ids.append([])\n",
    "\n",
    "    return cluster_ids, tokens_to_remove\n",
    "\n",
    "def filter_coref_mentions(tokens, cluster_ids, max_mention_len=4):\n",
    "    mentions = []\n",
    "    for mention in cluster_ids:\n",
    "        # if len(mention) == 0:\n",
    "            # print(cluster_ids, tokens, mention)\n",
    "        token_ids = []\n",
    "        start = mention[0]\n",
    "        while start < mention[-1]+1:\n",
    "            token = ''.join(tokens[start:start+3]).upper()\n",
    "            if token in ['<P>', '<A>', '<B>']:\n",
    "                start += 2\n",
    "            else:\n",
    "                token_ids.append(start)\n",
    "\n",
    "            start += 1\n",
    "\n",
    "        if len(token_ids) <= max_mention_len:\n",
    "            mentions.append(token_ids)\n",
    "\n",
    "    return mentions\n",
    "\n",
    "def extract_cluster_ids(ex_index, tokens, n_coref_models, max_mention_len=4, remove_gpr_tags=False):\n",
    "    gpr_tags = ['<P>', '<A>', '<B>']\n",
    "    if remove_gpr_tags:\n",
    "        tokens_ = []\n",
    "        start = 0\n",
    "        while start < len(tokens):\n",
    "            if ''.join(tokens[start:start+3]).upper() in gpr_tags:\n",
    "                start += 3\n",
    "            else:\n",
    "                tokens_.append(tokens[start])\n",
    "                start += 1\n",
    "        tokens = tokens_\n",
    "\n",
    "    cluster_tags = ['<C_{}>'.format(i) for i in range(n_coref_models)] + \\\n",
    "                        ['<D_{}>'.format(i) for i in range(n_coref_models)] + \\\n",
    "                        ['<E_{}>'.format(i) for i in range(n_coref_models)]\n",
    "\n",
    "    # map cluster ids to tokens so that we can make pairs and keep track of token ids for removal\n",
    "    map_idx_to_token = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        token = ''.join(tokens[start:start+5]).upper()\n",
    "\n",
    "        if token in cluster_tags:\n",
    "            mapping = (list(range(start, start+5)), token)\n",
    "            map_idx_to_token.append(mapping)\n",
    "        else:\n",
    "            map_idx_to_token.append(([start], tokens[start]))\n",
    "        start += 1\n",
    "\n",
    "    cluster_ids_a = [[[]] for i in range(n_coref_models)]\n",
    "    cluster_ids_b = [[[]] for i in range(n_coref_models)]\n",
    "    cluster_ids_p = [[[]] for i in range(n_coref_models)]\n",
    "    tokens_to_remove = []\n",
    "    for (token_ids, token) in map_idx_to_token:\n",
    "        if token in cluster_tags:\n",
    "            coref_model_idx = int(token[3])\n",
    "            if 'C' in token:\n",
    "                cluster_ids_a[coref_model_idx], tokens_to_remove = populate_cluster(cluster_ids_a[coref_model_idx], \n",
    "                                                                                    tokens_to_remove, \n",
    "                                                                                    token_ids)\n",
    "            if 'D' in token:\n",
    "                cluster_ids_b[coref_model_idx], tokens_to_remove = populate_cluster(cluster_ids_b[coref_model_idx], \n",
    "                                                                                    tokens_to_remove, \n",
    "                                                                                    token_ids)\n",
    "            if 'E' in token:\n",
    "                cluster_ids_p[coref_model_idx], tokens_to_remove = populate_cluster(cluster_ids_p[coref_model_idx], \n",
    "                                                                                    tokens_to_remove, \n",
    "                                                                                    token_ids)\n",
    "\n",
    "    for i in range(n_coref_models):\n",
    "        cluster_ids_a[i].pop()\n",
    "        cluster_ids_b[i].pop()\n",
    "        cluster_ids_p[i].pop()\n",
    "\n",
    "    # remove coref tags from tokens\n",
    "    for i, idx in enumerate(tokens_to_remove):\n",
    "        del tokens[idx-i]\n",
    "\n",
    "    # gather tokens between cluster tags\n",
    "    # filter out coref mention that are either a gpr tag or has tokens more than 6\n",
    "    for i in range(n_coref_models):\n",
    "        cluster_ids_a[i] = filter_coref_mentions(tokens, cluster_ids_a[i], max_mention_len=max_mention_len)\n",
    "        cluster_ids_b[i] = filter_coref_mentions(tokens, cluster_ids_b[i], max_mention_len=max_mention_len)\n",
    "        cluster_ids_p[i] = filter_coref_mentions(tokens, cluster_ids_p[i], max_mention_len=max_mention_len)\n",
    "\n",
    "    return tokens, cluster_ids_a, cluster_ids_b, cluster_ids_p\n",
    "\n",
    "def remove_first_matching_tag(tokens, tag):\n",
    "    start = 1\n",
    "    while start < len(tokens):\n",
    "        if ''.join(tokens[start:start+5]) == tag:\n",
    "            del tokens[start:start+5]\n",
    "            break\n",
    "        start += 1\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def get_sanitized_seq_len(tokens):\n",
    "    seq_len = 0\n",
    "    start = 0\n",
    "    tokens_ = []\n",
    "    while start < len(tokens):\n",
    "        if (''.join(tokens[start:start+3] + tokens[start+4:start+5])).upper() in ['<C_>', '<D_>', '<E_>']:\n",
    "            start += 5\n",
    "        else:\n",
    "            tokens_.append(tokens[start])\n",
    "            seq_len += 1\n",
    "            start += 1\n",
    "\n",
    "    return seq_len, tokens_\n",
    "\n",
    "def _truncate_seq(tokens, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # 1. First truncate the begining\n",
    "    # 2. truncate the end\n",
    "    # 3. truncate the middle\n",
    "\n",
    "    # map gpr tokens - cannot be removed\n",
    "    # if a token matches c or d, then don't consider it in sequence length\n",
    "    \n",
    "    gpr_tags = ['<P>', '<A>', '<B>']\n",
    "    cluster_tags = ['<C_>', '<D_>', '<E_>']\n",
    "    # 1 Start truncating from begining\n",
    "    #   if first token is not in gpr tags then remove it.\n",
    "    #       if it was a cluster tag, then remove the corresponding matching end tag as well\n",
    "    while get_sanitized_seq_len(tokens)[0] > max_length:\n",
    "        _, sanitized_tokens = get_sanitized_seq_len(tokens)\n",
    "\n",
    "        token = ''.join(sanitized_tokens[0:3]).upper()\n",
    "        if token not in gpr_tags:\n",
    "            # while first token is a cluster tag keep removing it and its matching end tag\n",
    "            while (''.join(tokens[:3] + tokens[4:5])).upper() in ['<C_>', '<D_>', '<E_>']:\n",
    "                tokens = remove_first_matching_tag(tokens, ''.join(tokens[:5]))\n",
    "                del tokens[:5]\n",
    "            del tokens[0]\n",
    "            continue\n",
    "\n",
    "        token = ''.join(sanitized_tokens[-3:]).upper()\n",
    "        if token not in gpr_tags:\n",
    "            # while last token is a cluster tag keep removing it and its matching start tag\n",
    "            while (''.join(tokens[-5:-2] + tokens[-1:])).upper() in ['<C_>', '<D_>', '<E_>']:\n",
    "                tokens_ = tokens[::-1]\n",
    "                tokens = remove_first_matching_tag(tokens_, ''.join(tokens_[:5]))\n",
    "                tokens = tokens[::-1]\n",
    "                del tokens[-5:]\n",
    "            del tokens[-1]\n",
    "            continue\n",
    "\n",
    "        raise Exception('Couldnt find a good way to truncate the sequence.')\n",
    "\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X,device,eval_mode=True):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in X], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in X], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in X], dtype=torch.long)\n",
    "    all_gpr_tags_mask = torch.tensor([f.gpr_tags_mask for f in X], dtype=torch.uint8)\n",
    "\n",
    "    all_mention_p_ids = torch.tensor([f.mention_p_ids for f in X], dtype=torch.long)\n",
    "    all_mention_a_ids = torch.tensor([f.mention_a_ids for f in X], dtype=torch.long)\n",
    "    all_mention_p_mask = torch.tensor([f.mention_p_mask for f in X], dtype=torch.uint8)\n",
    "    all_mention_a_mask = torch.tensor([f.mention_a_mask for f in X], dtype=torch.uint8)\n",
    "\n",
    "    all_cluster_ids_a = torch.tensor([f.cluster_ids_a for f in X], dtype=torch.long)\n",
    "    all_cluster_mask_a = torch.tensor([f.cluster_mask_a for f in X], dtype=torch.uint8)\n",
    "    all_cluster_ids_p = torch.tensor([f.cluster_ids_p for f in X], dtype=torch.long)\n",
    "    all_cluster_mask_p = torch.tensor([f.cluster_mask_p for f in X], dtype=torch.uint8)\n",
    "\n",
    "    all_pretrained = torch.tensor([f.pretrained for f in X], dtype=torch.float)\n",
    "    \n",
    "    all_label_ids = torch.tensor([f.label_id for f in X], dtype=torch.long)\n",
    "\n",
    "    eval_data = TensorDataset(all_input_ids, \n",
    "                                all_input_mask, \n",
    "                                all_segment_ids, \n",
    "                                all_gpr_tags_mask,\n",
    "                                all_mention_p_ids,\n",
    "                                all_mention_a_ids,\n",
    "                                all_mention_p_mask,\n",
    "                                all_mention_a_mask,\n",
    "                                all_cluster_ids_a,\n",
    "                                all_cluster_mask_a,\n",
    "                                all_cluster_ids_p,\n",
    "                                all_cluster_mask_p,\n",
    "                                all_pretrained,\n",
    "                                all_label_ids)\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, \n",
    "                                sampler=eval_sampler, \n",
    "                                batch_size=1)\n",
    "\n",
    "    eval_loss = 0\n",
    "    preds = []\n",
    "    attn_wts = []\n",
    "    pbar = tqdm(desc=\"Evaluating\", total=len(eval_dataloader)) if eval_mode else contextlib.suppress()\n",
    "    with pbar:\n",
    "        for step, batch in enumerate(eval_dataloader):\n",
    "            # with torch.cuda.device(0):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            (input_ids, input_mask, segment_ids, \n",
    "                gpr_tags_mask,\n",
    "                mention_p_ids, mention_a_ids,\n",
    "                mention_p_mask, mention_a_mask,\n",
    "                cluster_ids_a, cluster_mask_a,\n",
    "                cluster_ids_p, cluster_mask_p, pretrained, label_ids) = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                res = model(input_ids,\n",
    "                            segment_ids, \n",
    "                            input_mask, \n",
    "                            gpr_tags_mask=gpr_tags_mask,\n",
    "                            mention_p_ids=mention_p_ids,\n",
    "                            mention_a_ids=mention_a_ids,\n",
    "                            mention_p_mask=mention_p_mask,\n",
    "                            mention_a_mask=mention_a_mask, \n",
    "                            cluster_ids_a=cluster_ids_a,\n",
    "                            cluster_mask_a=cluster_mask_a,\n",
    "                            cluster_ids_p=cluster_ids_p,\n",
    "                            cluster_mask_p=cluster_mask_p,\n",
    "                            pretrained=pretrained,\n",
    "                            labels=None,\n",
    "                            training=False,\n",
    "                            eval_mode=eval_mode\n",
    "                        )\n",
    "\n",
    "                if eval_mode:\n",
    "                    logits, probabilties, attn_wts_m, attn_wts_c, attn_wts_co = res\n",
    "                else:\n",
    "                    logits, probabilties = res\n",
    "\n",
    "            if len(preds) == 0:\n",
    "                preds.append(probabilties.detach().cpu().numpy())\n",
    "            else:\n",
    "                preds[0] = np.append(preds[0], probabilties.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "            if eval_mode:\n",
    "                pbar.update()\n",
    "\n",
    "                if len(attn_wts) == 0:\n",
    "                    attn_wts = [attn_wts_m, attn_wts_c]\n",
    "                else:\n",
    "                    attn_wts[0] = np.append(attn_wts[0], attn_wts_m, axis=0)\n",
    "                    attn_wts[1] = np.append(attn_wts[1], attn_wts_c, axis=0)\n",
    "\n",
    "    preds = preds[0]\n",
    "    return preds, attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize results data frame\n",
    "tmp_write_path = \"tmp_df.csv\"\n",
    "filename_wr = 'df_output_hf.csv'\n",
    "labels = [True,False]\n",
    "\n",
    "def process_input(input_text: str | list):\n",
    "    cols = ['id', 'text', 'pronoun', 'pronoun_offset', 'a', 'a_offset', 'url']\n",
    "    output_cols = ['id', 'text', 'pronoun', 'pronoun_offset', 'a', 'a_offset', 'a_coref', 'url', 'probabilities', 'output']\n",
    "    df_list = []\n",
    "    if isinstance(input_text, str):\n",
    "        entity_list, pronoun_list = get_entities_and_pronouns([input_text])\n",
    "        original_text = [input_text]\n",
    "    elif isinstance(input_text, list):\n",
    "        original_text = input_text\n",
    "        entity_list, pronoun_list = get_entities_and_pronouns(input_text)\n",
    "    else:\n",
    "        raise \n",
    "    print(entity_list, pronoun_list)      \n",
    "    if not pronoun_list[-1] or not entity_list[-1]:\n",
    "        return \"no pronouns present\"\n",
    "    else:\n",
    "        for i in range(len(original_text)):\n",
    "            combinations = get_combinations(entity_list[i], pronoun_list[i])\n",
    "            for combination in combinations:\n",
    "                pronoun, pronoun_offset = combination[0], combination[1]\n",
    "                entity1, entity1_offset = combination[2], combination[3]\n",
    "                \n",
    "                df_list.append([i,original_text[i], pronoun,pronoun_offset,entity1,entity1_offset,'na'])\n",
    "\n",
    "        df = pd.DataFrame(df_list, columns=cols)\n",
    "        df.to_csv(tmp_write_path, sep='\\t', index=False)\n",
    "        # display(df)\n",
    "        X_annotated = transform(df)\n",
    "        # Tokenisation of the text happens here\n",
    "        X = convert_examples_to_features(X_annotated,tokenizer,512,n_coref_models=0,verbose=0)\n",
    "        # inference using model\n",
    "        predicted_probs, _ = predict(model,X,device,eval_mode=True)\n",
    "        # index of max value from predictions so we get exact entity name it resolves to\n",
    "        output_list = []\n",
    "        for idx, row in df.iterrows():\n",
    "            id = row['id']\n",
    "            pronoun = row['pronoun']\n",
    "            pronoun_offset = row['pronoun_offset']\n",
    "            entity1 = row['a']\n",
    "            entity1_offset = row['a_offset']\n",
    "            text = row['text']\n",
    "            probs = predicted_probs[idx]\n",
    "            max_idx = list(probs).index(max(probs))\n",
    "            \n",
    "            output = f\"Known pronoun '{pronoun}' resolves '{labels[max_idx]}' to '{entity1}' with a probability of '{probs[max_idx]}'\"\n",
    "            print(output)\n",
    "            entity_coref = labels[max_idx]\n",
    "            output_list.append([id,text, pronoun,pronoun_offset,entity1,entity1_offset,entity_coref,'na', probs, output])\n",
    "        \n",
    "\n",
    "        df_output = pd.DataFrame(output_list, columns=output_cols)\n",
    "        df_output.to_csv(filename_wr, index=False)\n",
    "        # display(df_output)\n",
    "        return df_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPR Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Run the git gpr_pub clone only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gpr_pub'...\n",
      "remote: Enumerating objects: 301, done.\u001b[K\n",
      "remote: Total 301 (delta 0), reused 0 (delta 0), pack-reused 301\u001b[K\n",
      "Receiving objects: 100% (301/301), 5.36 MiB | 35.20 MiB/s, done.\n",
      "Resolving deltas: 100% (132/132), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sattree/gpr_pub.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".highlight {\n",
       "  border: 2px solid;\n",
       "  color: #232323;\n",
       "  margin: 4px 6px 4px 3px;\n",
       "  vertical-align: middle;\n",
       "  box-shadow: 2px 4px 20px rgba(0,0,0,0.1);\n",
       "  position: relative;\n",
       "  cursor: default;\n",
       "  min-width: 26px;\n",
       "  line-height: 22px;\n",
       "  display: inline-flex;\n",
       "}\n",
       "\n",
       ".highlight:last-child {\n",
       "  margin-right: 4px;\n",
       "}\n",
       "\n",
       ".highlight:first-child {\n",
       "  margin-left: 0;\n",
       "}\n",
       "\n",
       ".highlight,\n",
       ".highlight span {\n",
       "  transition: background-color .1s ease,\n",
       "              color .1s ease,\n",
       "              box-shadow .1s ease,\n",
       "              opacity .1s ease;\n",
       "}\n",
       "\n",
       ".highlight.short-text {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".highlight__label {\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  padding: 0 8px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "}\n",
       "\n",
       ".highlight__label strong,\n",
       ".highlight__label span.highlight__label__secondary-label {\n",
       "  display: block;\n",
       "  font-size: 11px;\n",
       "  color: #fff;\n",
       "  -webkit-font-smoothing: subpixel-antialiased;\n",
       "  letter-spacing: 0.1em;\n",
       "}\n",
       "\n",
       ".highlight__label strong {\n",
       "  text-transform: uppercase;\n",
       "}\n",
       "\n",
       ".highlight__label span.highlight__label__secondary-label {\n",
       "  opacity: .75;\n",
       "  padding-left: 6px;\n",
       "}\n",
       "\n",
       ".highlight__content {\n",
       "  flex-wrap: wrap;\n",
       "  align-items: center;\n",
       "  padding: 2px 2px 2px 6px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight-container.highlight-container--bottom-labels .highlight.bottom {\n",
       "  margin-top: 6px;\n",
       "}\n",
       "\n",
       ".highlight.bottom {\n",
       "  display: block;\n",
       "  white-space: normal;\n",
       "}\n",
       "\n",
       ".highlight.bottom .highlight__content:after {\n",
       "  content: \" \";\n",
       "  padding-right: 3px;\n",
       "}\n",
       "\n",
       ".highlight.bottom .highlight__label {\n",
       "  line-height: 14px;\n",
       "  padding-top: 1px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.top {\n",
       "  flex-direction: column;\n",
       "  white-space: normal;\n",
       "}\n",
       "\n",
       ".highlight.top .highlight__label {\n",
       "  min-height: 22px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.active,\n",
       ".highlight.active span {\n",
       "  color: #fff;\n",
       "}\n",
       "\n",
       ".highlight.active .highlight:not(.active) span {\n",
       "  color: #232323;\n",
       "}\n",
       "\n",
       ".highlight.clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight.clickable.clickable.selected {\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       ".highlight.clickable.clicking {\n",
       "  opacity: 0.66;\n",
       "  transition-duration: 0s;\n",
       "}\n",
       "\n",
       ".clicking .highlight,\n",
       ".clicking .highlight span,\n",
       ".clicking .highlight:before,\n",
       ".clicking .highlight:after {\n",
       "  transition-duration: 0s;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.gray {\n",
       "  background: #f2f4f6;\n",
       "}\n",
       "\n",
       ".highlight.gray,\n",
       ".highlight-arrow--gray .highlight-arrow__triangle {\n",
       "  border-color: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray .highlight__label,\n",
       ".highlight-arrow--gray .highlight-arrow__stalk,\n",
       ".highlight.gray .highlight__button .highlight__button__body {\n",
       "  background-color: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray.active {\n",
       "  background: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray.active .highlight__label {\n",
       "  background-color: #aab3bd;\n",
       "}\n",
       "\n",
       ".highlight.gray .highlight__button svg {\n",
       "  fill: #a0aab5;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".highlight.blue {\n",
       "  background: #edf4fa;\n",
       "}\n",
       "\n",
       ".highlight.blue,\n",
       ".highlight-arrow--blue .highlight-arrow__triangle {\n",
       "  border-color: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue > .highlight__label,\n",
       ".highlight-arrow--blue .highlight-arrow__stalk,\n",
       ".highlight.blue .highlight__button .highlight__button__body {\n",
       "  background-color: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue.active {\n",
       "  background: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue.active > .highlight__label {\n",
       "  background-color: #5fb9f8;\n",
       "}\n",
       "\n",
       ".highlight.blue .highlight__button svg {\n",
       "  fill: #4db1f7;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.green {\n",
       "  background: #f1f4f1;\n",
       "}\n",
       "\n",
       ".highlight.green,\n",
       ".highlight-arrow--green .highlight-arrow__triangle {\n",
       "  border-color: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green > .highlight__label,\n",
       ".highlight-arrow--green .highlight-arrow__stalk,\n",
       ".highlight.green .highlight__button .highlight__button__body {\n",
       "  background-color: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green.active {\n",
       "  background: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green.active > .highlight__label {\n",
       "  background-color: #9bb460;\n",
       "}\n",
       "\n",
       ".highlight.green .highlight__button svg {\n",
       "  fill: #90ac4e;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.pink {\n",
       "  background: #f4f1f4;\n",
       "}\n",
       "\n",
       ".highlight.pink,\n",
       ".highlight-arrow--pink .highlight-arrow__triangle {\n",
       "  border-color: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink > .highlight__label,\n",
       ".highlight-arrow--pink .highlight-arrow__stalk,\n",
       ".highlight.pink .highlight__button .highlight__button__body {\n",
       "  background-color: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink.active {\n",
       "  background: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink.active > .highlight__label {\n",
       "  background-color: #d37593;\n",
       "}\n",
       "\n",
       ".highlight.pink .highlight__button svg {\n",
       "  fill: #ce6587;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.orange {\n",
       "  background: #f2f4f4;\n",
       "}\n",
       "\n",
       ".highlight.orange,\n",
       ".highlight-arrow--orange .highlight-arrow__triangle {\n",
       "  border-color: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange > .highlight__label,\n",
       ".highlight-arrow--orange .highlight-arrow__stalk,\n",
       ".highlight.orange .highlight__button .highlight__button__body {\n",
       "  background-color: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange.active {\n",
       "  background: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange.active > .highlight__label {\n",
       "  background-color: #e0a852;\n",
       "}\n",
       "\n",
       ".highlight.orange .highlight__button svg {\n",
       "  fill: #dd9e3e;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.purple {\n",
       "  background: #f1f0f7;\n",
       "}\n",
       "\n",
       ".highlight.purple,\n",
       ".highlight-arrow--purple .highlight-arrow__triangle {\n",
       "  border-color: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple > .highlight__label,\n",
       ".highlight-arrow--purple .highlight-arrow__stalk,\n",
       ".highlight.purple .highlight__button .highlight__button__body {\n",
       "  background-color: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple.active {\n",
       "  background: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple.active > .highlight__label {\n",
       "  background-color: #a46ec1;\n",
       "}\n",
       "\n",
       ".highlight.purple .highlight__button svg {\n",
       "  fill: #9a5eba;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.teal {\n",
       "  background: #eef4f6;\n",
       "}\n",
       "\n",
       ".highlight.teal,\n",
       ".highlight-arrow--teal .highlight-arrow__triangle {\n",
       "  border-color: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal > .highlight__label,\n",
       ".highlight-arrow--teal .highlight-arrow__stalk,\n",
       ".highlight.teal .highlight__button .highlight__button__body {\n",
       "  background-color: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal.active {\n",
       "  background: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal.active > .highlight__label {\n",
       "  background-color: #6cb9b5;\n",
       "}\n",
       "\n",
       ".highlight.teal .highlight__button svg {\n",
       "  fill: #5bb1ad;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.tan {\n",
       "  background: #f2f4f4;\n",
       "}\n",
       "\n",
       ".highlight.tan,\n",
       ".highlight-arrow--tan .highlight-arrow__triangle {\n",
       "  border-color: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan > .highlight__label,\n",
       ".highlight-arrow--tan .highlight-arrow__stalk,\n",
       ".highlight.tan .highlight__button .highlight__button__body {\n",
       "  background-color: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan.active {\n",
       "  background: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan.active > .highlight__label {\n",
       "  background-color: #b8ad8e;\n",
       "}\n",
       "\n",
       ".highlight.tan .highlight__button svg {\n",
       "  fill: #b0a481;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.red {\n",
       "  background: #f5eef0;\n",
       "}\n",
       "\n",
       ".highlight.red,\n",
       ".highlight-arrow--red .highlight-arrow__triangle {\n",
       "  border-color: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red > .highlight__label,\n",
       ".highlight-arrow--red .highlight-arrow__stalk,\n",
       ".highlight.red .highlight__button .highlight__button__body {\n",
       "  background-color: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red.active {\n",
       "  background: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red.active > .highlight__label {\n",
       "  background-color: #e24c4c;\n",
       "}\n",
       "\n",
       ".highlight.red .highlight__button svg {\n",
       "  fill: #df3838;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.cobalt {\n",
       "  background: #eef0f5;\n",
       "}\n",
       "\n",
       ".highlight.cobalt,\n",
       ".highlight-arrow--cobalt .highlight-arrow__triangle {\n",
       "  border-color: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt > .highlight__label,\n",
       ".highlight-arrow--cobalt .highlight-arrow__stalk,\n",
       ".highlight.cobalt .highlight__button .highlight__button__body {\n",
       "  background-color: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt.active {\n",
       "  background: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt.active > .highlight__label {\n",
       "  background-color: #6f6ca2;\n",
       "}\n",
       "\n",
       ".highlight.cobalt .highlight__button svg {\n",
       "  fill: #5f5b97;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.brown {\n",
       "  background: #f2f4f6;\n",
       "}\n",
       "\n",
       ".highlight.brown,\n",
       ".highlight-arrow--brown .highlight-arrow__triangle {\n",
       "  border-color: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown > .highlight__label,\n",
       ".highlight-arrow--brown .highlight-arrow__stalk,\n",
       ".highlight.brown .highlight__button .highlight__button__body {\n",
       "  background-color: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown.active {\n",
       "  background: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown.active > .highlight__label {\n",
       "  background-color: #796051;\n",
       "}\n",
       "\n",
       ".highlight.brown .highlight__button svg {\n",
       "  fill: #6a4e3d;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.slate {\n",
       "  background: #eceff1;\n",
       "}\n",
       "\n",
       ".highlight.slate,\n",
       ".highlight-arrow--slate .highlight-arrow__triangle {\n",
       "  border-color: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate > .highlight__label,\n",
       ".highlight-arrow--slate .highlight-arrow__stalk,\n",
       ".highlight.slate .highlight__button .highlight__button__body {\n",
       "  background-color: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate.active {\n",
       "  background: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate.active > .highlight__label {\n",
       "  background-color: #4f555a;\n",
       "}\n",
       "\n",
       ".highlight.slate .highlight__button svg {\n",
       "  fill: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia {\n",
       "  background: #f5f1f9;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia,\n",
       ".highlight-arrow--fuchsia .highlight-arrow__triangle {\n",
       "  border-color: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia > .highlight__label,\n",
       ".highlight-arrow--fuchsia .highlight-arrow__stalk,\n",
       ".highlight.fuchsia .highlight__button .highlight__button__body {\n",
       "  background-color: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia.active {\n",
       "  background: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia.active > .highlight__label {\n",
       "  background-color: #ea83ea;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia .highlight__button svg {\n",
       "  fill: #e875e8;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight__tooltip {\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  box-shadow: 0 0 30px rgba(0,0,0,.2);\n",
       "  border-radius: 6px;\n",
       "  background: rgba(70,70,70,.9);\n",
       "  padding: 4px 9px 5px 9px;\n",
       "  opacity: 0;\n",
       "  z-index: -9;\n",
       "  left: 50%;\n",
       "  top: 100%;\n",
       "  margin-top: 10px;\n",
       "  font-size: 14px;\n",
       "  color: #fff;\n",
       "  transform: translate(-50%, -6px);\n",
       "  transition: opacity .2s ease,\n",
       "              z-index .2s ease,\n",
       "              transform .2s ease .3s;\n",
       "  font-weight: bold;\n",
       "  white-space: nowrap;\n",
       "  user-select: none;\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       ".highlight__tooltip:before {\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  left: 50%;\n",
       "  top: 0;\n",
       "  margin-top: -6px;\n",
       "  margin-left: -6px;\n",
       "  content: \"\";\n",
       "  width: 0;\n",
       "  height: 0;\n",
       "  border-style: solid;\n",
       "  border-width: 0 6px 6px 6px;\n",
       "  border-color: transparent transparent rgba(70,70,70,.9) transparent;\n",
       "}\n",
       "\n",
       ".highlight:hover .highlight__tooltip {\n",
       "  z-index: 9;\n",
       "  opacity: 1;\n",
       "  transform: translate(-50%, 0);\n",
       "  transition-delay: 0s;\n",
       "}\n",
       "\n",
       ".highlight__tooltip:hover {\n",
       "  z-index: -9 !important;\n",
       "}\n",
       "\n",
       ".highlight-container {\n",
       "  line-height: 42px !important;\n",
       "  align-items: center;\n",
       "  display: flex;\n",
       "  flex-wrap: wrap;\n",
       "  white-space: pre;\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight-container.highlight-container--bottom-labels {\n",
       "  padding: 10px 1.125em;\n",
       "  align-items: flex-start;\n",
       "}\n",
       "\n",
       ".highlight-container.highlight-container--diagram {\n",
       "  align-items: flex-start;\n",
       "}\n",
       "\n",
       ".highlight-container.highlight-container--diagram.passage.model__content__summary {\n",
       "  background: transparent;\n",
       "  align-items: stretch;\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    \n",
       "function handleHighlightMouseOver(el) {\n",
       "    $('[id='+el.getAttribute('id')+']').addClass('active');\n",
       "  }\n",
       "\n",
       "function handleHighlightMouseOut(el) {\n",
       "    $('[id='+el.getAttribute('id')+']').removeClass('active');\n",
       "}\n",
       "  \n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from gpr_pub import visualization\n",
    "\n",
    "# Add css styles and js events to DOM, so that they are available to rendered html\n",
    "display(HTML(open('gpr_pub/visualization/highlight.css').read()))\n",
    "display(HTML(open('gpr_pub/visualization/highlight.js').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelled_pronoun(row):\n",
    "    txt = row.text\n",
    "    prob = row.probabilities[0]\n",
    "\n",
    "    # map char indices to token indices\n",
    "    tokens = txt.split(' ')\n",
    "    start_a = len(txt[:row.a_offset].split(' '))-1\n",
    "\n",
    "    clusters = [[[start_a, start_a+len(row.a.split(' '))-1]]]\n",
    "\n",
    "    # add pronoun token to the labelled cluster\n",
    "    start_p = len(txt[:row.pronoun_offset].split(' '))-1\n",
    "    if row.a_coref:\n",
    "        clusters[0].append([start_p, start_p+len(row.pronoun.split(' '))-1])\n",
    "    else:\n",
    "        clusters.append([[start_p, start_p+len(row.pronoun.split(' '))-1]])\n",
    "\n",
    "    tokens[start_p] = tokens[start_p] + f\" ({prob:.2f} probability)\"\n",
    "    return tokens, clusters\n",
    "\n",
    "def to_html(tokens, clusters):\n",
    "    tree = visualization.html_template.transform_to_tree(tokens, clusters)\n",
    "    html = ''.join(visualization.html_template.span_wrapper(tree, 0))\n",
    "    html = '<div style=\"padding: 16px;\">{}</div>'.format(html)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gpr_visual(eval_data_plot):\n",
    "    rows = []\n",
    "    for idx, row in eval_data_plot.iterrows():\n",
    "        # Special rendering for labelled pronouns\n",
    "        # labels in 'a_coref'\n",
    "        tokens, clusters = labelled_pronoun(row)\n",
    "        html = to_html(tokens, clusters)\n",
    "        rows.append({'sample_idx': idx,\n",
    "                    'text': row.text,\n",
    "                    'annotation': html})\n",
    "\n",
    "    df = pd.DataFrame(rows).groupby(['sample_idx']).agg(lambda x: x)\n",
    "    s = df.style.set_properties(**{'text-align': 'left'})\n",
    "    display(HTML(s.to_html(justify='left')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spacy Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 13:26:53.564113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 13:26:55.314992: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "    \n",
    "def ex_tags(df):\n",
    "    # ex = []\n",
    "    ex = {\"text\":[], \"value\": []}\n",
    "    for idx, row in df.iterrows():\n",
    "        txt = ' '.join(' '.join(row.text.strip().split(\" \")).split())\n",
    "        start_a = len(txt[:row.a_offset].split(' '))-1\n",
    "        start_p = len(txt[:row.pronoun_offset].split(' '))-1\n",
    "        if not txt in ex[\"text\"]:\n",
    "            ex[\"text\"].append(txt)\n",
    "            ex_val_dict = {\"words\": [], \"arcs\": []}\n",
    "            tokens = txt.split()\n",
    "            for i,t in enumerate(tokens):\n",
    "                if t.strip() != '' and t.strip() in row.a:\n",
    "                    ex_val_dict[\"words\"].append({\"text\": t, \"tag\": \"entity\"})\n",
    "                    if start_a < start_p:\n",
    "                        arc = {\"start\": start_a, \"end\": start_p, \"label\": row.a_coref, \"dir\":\"left\"}\n",
    "                    else:\n",
    "                        arc = {\"start\": start_a, \"end\": start_p, \"label\": row.a_coref, \"dir\":\"right\"}\n",
    "                    if not arc in ex_val_dict[\"arcs\"]:\n",
    "                        ex_val_dict[\"arcs\"].append(arc)      \n",
    "                else:\n",
    "                    ex_val_dict[\"words\"].append({\"text\": t, \"tag\": f\"token_{i}\"})   \n",
    "            ex[\"value\"].append(ex_val_dict)\n",
    "        else:\n",
    "            text_idx = ex[\"text\"].index(txt)\n",
    "            arc = {\"start\": start_a, \"end\": start_p, \"label\": row.a_coref, \"dir\":\"left\"}\n",
    "            if not arc in ex[\"value\"][text_idx][\"arcs\"]:\n",
    "                ex[\"value\"][text_idx][\"arcs\"].append(arc)      \n",
    "    return ex[\"value\"]\n",
    "\n",
    "def plot_spacy(eval_data_plot):\n",
    "    ex_to_use = ex_tags(eval_data_plot)\n",
    "    html = displacy.render(ex_to_use, style=\"dep\", manual=True, jupyter=True)\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Process Detection Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ambiguity_class(text):\n",
    "    # function to yeild the detection\n",
    "    def pcd(eval_data_plot):\n",
    "        if \"no pronouns\" in eval_data_plot:\n",
    "            yield {\"ambiguity_present\": False, \"associated_pronouns\": None}\n",
    "        else:\n",
    "            binary = False\n",
    "            non_binary = False\n",
    "            e_group = eval_data_plot.groupby(['id','a_offset'])[['a', 'pronoun', 'a_coref', 'probabilities', 'text']].apply(lambda x: x)\n",
    "            # #select only case where the pronoun coreferences the named entity.\n",
    "            # e_group = e_group.loc[(e_group['a_coref'] == True)]\n",
    "            plot_gpr_visual(eval_data_plot)\n",
    "            group_pronoun = set()\n",
    "            for idx, row in e_group.iterrows():\n",
    "                group_pronoun.add(row.pronoun)\n",
    "                if row.pronoun in binary_pronouns:\n",
    "                    binary = True\n",
    "                else:\n",
    "                    non_binary = True\n",
    "            yield {\"ambiguity_present\": binary == non_binary, \"mean_probability\":np.mean(e_group.probabilities, axis=0)[0],\"named_entity\":row.a, \"associated_pronouns\":group_pronoun}\n",
    "\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        eval_data_plot = process_input(text)\n",
    "        detected = [i for i in pcd(eval_data_plot)]\n",
    "        yield detected[0]\n",
    "    elif isinstance(text, dict):\n",
    "        if \"input\" in text.keys() and \"output\" in text.keys():\n",
    "            eval_data_plot_input = process_input(text[\"input\"])\n",
    "            input = [i for i in pcd(eval_data_plot_input)]\n",
    "            eval_data_plot_output = process_input(text[\"output\"])\n",
    "            output = [i for i in pcd(eval_data_plot_output)]\n",
    "            if input[0][\"associated_pronouns\"] == None and output[0][\"associated_pronouns\"] != None:\n",
    "                yield {\"ambiguity_present\": True, \"mean_probability\":output[0][\"mean_probability\"], \"named_entity\":output[0][\"named_entity\"], \"associated_pronouns\":output[0][\"associated_pronouns\"]}\n",
    "            else:\n",
    "                yield output[0]\n",
    "        else:\n",
    "            raise \"input dictionary doesn't contain the required input and output keys\"\n",
    "    else:\n",
    "        raise \"Can only process raw strings or a dictionary of input and output strings.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ambiguity** Concept (dictionary): the quality of being open to more than one interpretation. \n",
    "\n",
    "**Hypothesis made**: A named entity in a given contextual sentence is referenced either by non-binary or binary gendered pronouns. Can't be both in same sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Pat': [0], 'Lami': [21]}] [{}]\n",
      "\n",
      "Gender Ambiguity:  {'ambiguity_present': False, 'associated_pronouns': None}\n"
     ]
    }
   ],
   "source": [
    "input_0 = \"Pat was not sure how Lami should bring up inclusivity in the workplace. \"\n",
    "is_gap_present = get_ambiguity_class(input_0)\n",
    "for gap in is_gap_present:\n",
    "    print(\"\\nGender Ambiguity: \", gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unambiguous pronouns sentence context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Pat': [0]}] [{'they': [21]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 814.74it/s]\n",
      "Convert Examples to features: 1it [00:00, 749.12it/s]\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]/u/lamogha/.cache/huggingface/modules/transformers_modules/ibm/probert/881f97f5e7942ed6bb57b591acc56af5fe579d51/probert.py:66: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1680572619157/work/aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  sequence_output = sequence_output[~gpr_tags_mask].view(batch_size, -1, self.config.hidden_size)\n",
      "Evaluating: 100%|| 1/1 [00:06<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known pronoun 'they' resolves 'True' to 'Pat' with a probability of '0.506740152835846'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f65b2_row0_col0, #T_f65b2_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f65b2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f65b2_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_f65b2_level0_col1\" class=\"col_heading level0 col1\" >annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >sample_idx</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f65b2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f65b2_row0_col0\" class=\"data row0 col0\" >Pat was not sure how they should bring up inclusivity in the workplace, because </td>\n",
       "      <td id=\"T_f65b2_row0_col1\" class=\"data row0 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span key=5 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>they (0.51 probability) </span></span></span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span> </span></div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender Ambiguity:  {'ambiguity_present': False, 'mean_probability': 0.50674015, 'named_entity': 'Pat', 'associated_pronouns': {'they'}}\n"
     ]
    }
   ],
   "source": [
    "input_1 = \"Pat was not sure how they should bring up inclusivity in the workplace, because \"\n",
    "is_gap_present = get_ambiguity_class(input_1)\n",
    "for gap in is_gap_present:\n",
    "    print(\"\\nGender Ambiguity: \", gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambiguous pronouns in sentence context (input + output as one string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Pat': [0, 80]}] [{'they': [21], 'she': [101], 'it': [118]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:00<00:00, 3390.25it/s]\n",
      "Convert Examples to features: 6it [00:00, 2060.41it/s]\n",
      "Evaluating:   0%|          | 0/6 [00:00<?, ?it/s]/u/lamogha/.cache/huggingface/modules/transformers_modules/ibm/probert/881f97f5e7942ed6bb57b591acc56af5fe579d51/probert.py:66: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1680572619157/work/aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  sequence_output = sequence_output[~gpr_tags_mask].view(batch_size, -1, self.config.hidden_size)\n",
      "Evaluating: 100%|| 6/6 [00:00<00:00, 20.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known pronoun 'they' resolves 'True' to 'Pat' with a probability of '0.9659983515739441'\n",
      "Known pronoun 'they' resolves 'True' to 'Pat' with a probability of '0.9833201766014099'\n",
      "Known pronoun 'she' resolves 'True' to 'Pat' with a probability of '0.9681033492088318'\n",
      "Known pronoun 'she' resolves 'True' to 'Pat' with a probability of '0.9982727766036987'\n",
      "Known pronoun 'it' resolves 'False' to 'Pat' with a probability of '0.860580563545227'\n",
      "Known pronoun 'it' resolves 'True' to 'Pat' with a probability of '0.6779956817626953'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8e449_row0_col0, #T_8e449_row0_col1, #T_8e449_row1_col0, #T_8e449_row1_col1, #T_8e449_row2_col0, #T_8e449_row2_col1, #T_8e449_row3_col0, #T_8e449_row3_col1, #T_8e449_row4_col0, #T_8e449_row4_col1, #T_8e449_row5_col0, #T_8e449_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8e449\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8e449_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_8e449_level0_col1\" class=\"col_heading level0 col1\" >annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >sample_idx</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8e449_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8e449_row0_col0\" class=\"data row0 col0\" >Pat was not sure how they should bring up inclusivity in the workplace, because Pat was not sure how she should bring it up.</td>\n",
       "      <td id=\"T_8e449_row0_col1\" class=\"data row0 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span key=5 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>they (0.97 probability) </span></span></span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span>Pat </span><span>was </span><span>not </span><span>sure </span><span>how </span><span>she </span><span>should </span><span>bring </span><span>it </span><span>up. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e449_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8e449_row1_col0\" class=\"data row1 col0\" >Pat was not sure how they should bring up inclusivity in the workplace, because Pat was not sure how she should bring it up.</td>\n",
       "      <td id=\"T_8e449_row1_col1\" class=\"data row1 col1\" ><div style=\"padding: 16px;\"><span>Pat </span><span>was </span><span>not </span><span>sure </span><span>how </span><span key=5 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>they (0.98 probability) </span></span></span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span key=14 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span>she </span><span>should </span><span>bring </span><span>it </span><span>up. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e449_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8e449_row2_col0\" class=\"data row2 col0\" >Pat was not sure how they should bring up inclusivity in the workplace, because Pat was not sure how she should bring it up.</td>\n",
       "      <td id=\"T_8e449_row2_col1\" class=\"data row2 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span>they </span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span>Pat </span><span>was </span><span>not </span><span>sure </span><span>how </span><span key=19 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>she (0.97 probability) </span></span></span><span>should </span><span>bring </span><span>it </span><span>up. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e449_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8e449_row3_col0\" class=\"data row3 col0\" >Pat was not sure how they should bring up inclusivity in the workplace, because Pat was not sure how she should bring it up.</td>\n",
       "      <td id=\"T_8e449_row3_col1\" class=\"data row3 col1\" ><div style=\"padding: 16px;\"><span>Pat </span><span>was </span><span>not </span><span>sure </span><span>how </span><span>they </span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span key=14 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span key=19 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>she (1.00 probability) </span></span></span><span>should </span><span>bring </span><span>it </span><span>up. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e449_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8e449_row4_col0\" class=\"data row4 col0\" >Pat was not sure how they should bring up inclusivity in the workplace, because Pat was not sure how she should bring it up.</td>\n",
       "      <td id=\"T_8e449_row4_col1\" class=\"data row4 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span>they </span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span>Pat </span><span>was </span><span>not </span><span>sure </span><span>how </span><span>she </span><span>should </span><span>bring </span><span key=22 class=\"highlight green\" depth=0 id=1 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>1</strong></span>                <span class=\"highlight__content\"><span>it (0.14 probability) </span></span></span><span>up. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e449_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8e449_row5_col0\" class=\"data row5 col0\" >Pat was not sure how they should bring up inclusivity in the workplace, because Pat was not sure how she should bring it up.</td>\n",
       "      <td id=\"T_8e449_row5_col1\" class=\"data row5 col1\" ><div style=\"padding: 16px;\"><span>Pat </span><span>was </span><span>not </span><span>sure </span><span>how </span><span>they </span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span key=14 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span>she </span><span>should </span><span>bring </span><span key=22 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>it (0.68 probability) </span></span></span><span>up. </span></div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender Ambiguity:  {'ambiguity_present': True, 'mean_probability': 0.7888517, 'named_entity': 'Pat', 'associated_pronouns': {'it', 'they', 'she'}}\n"
     ]
    }
   ],
   "source": [
    "output_1 = \"Pat was not sure how they should bring up inclusivity in the workplace, because Pat was not sure how she should bring it up.\"\n",
    "is_gap_present = get_ambiguity_class(output_1)\n",
    "for gap in is_gap_present:\n",
    "    print(\"\\nGender Ambiguity: \", gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambiguous pronoun in output when no pronoun in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Pat': [0]}] [{}]\n",
      "[{'Pat': [0]}] [{'she': [61]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 1263.73it/s]\n",
      "Convert Examples to features: 1it [00:00, 1283.45it/s]\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]/u/lamogha/.cache/huggingface/modules/transformers_modules/ibm/probert/881f97f5e7942ed6bb57b591acc56af5fe579d51/probert.py:66: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1680572619157/work/aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  sequence_output = sequence_output[~gpr_tags_mask].view(batch_size, -1, self.config.hidden_size)\n",
      "Evaluating: 100%|| 1/1 [00:00<00:00, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known pronoun 'she' resolves 'True' to 'Pat' with a probability of '0.9941904544830322'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_101af_row0_col0, #T_101af_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_101af\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_101af_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_101af_level0_col1\" class=\"col_heading level0 col1\" >annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >sample_idx</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_101af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_101af_row0_col0\" class=\"data row0 col0\" >Pat was not sure about inclusivity in the workplace, because she was away during the training.</td>\n",
       "      <td id=\"T_101af_row0_col1\" class=\"data row0 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>about </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace, </span><span>because </span><span key=10 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>she (0.99 probability) </span></span></span><span>was </span><span>away </span><span>during </span><span>the </span><span>training. </span></div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender Ambiguity:  {'ambiguity_present': True, 'mean_probability': 0.99419045, 'named_entity': 'Pat', 'associated_pronouns': {'she'}}\n"
     ]
    }
   ],
   "source": [
    "input_1 = {\"input\": \"Pat was not sure about inclusivity in the workplace\", \"output\": \"Pat was not sure about inclusivity in the workplace, because she was away during the training.\"}\n",
    "is_gap_present = get_ambiguity_class(input_1)\n",
    "for gap in is_gap_present:\n",
    "    print(\"\\nGender Ambiguity: \", gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Clean up after\n",
    "!rm -rf gpr_pub/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
