{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "# !pip install torch\n",
    "# !pip install transformers==4.34.0\n",
    "# !pip install pycorenlp==0.3.0\n",
    "# !pip install python-dotenv==1.0.0\n",
    "# !pip install pytorch-pretrained-bert==0.6.2\n",
    "# !pip install pandas==2.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub.hf_api import HfFolder \n",
    "import os, json, re, contextlib\n",
    "# import AttrDict\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch.utils.data import DataLoader, SequentialSampler,TensorDataset\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "class AttrDict(dict):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# private hf model token needed. give write persmission if push to hub is expected\n",
    "# save in .env file with HF_TOKEN key\n",
    "# see https://huggingface.co/docs/transformers.js/guides/private\n",
    "HfFolder.save_token(os.environ.get(\"HF_TOKEN\"))\n",
    "os.environ['TRANSFORMERS_CACHE'] = './cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProBERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not False else \"cpu\")\n",
    "# Load tokenizer and model directly from hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ibm/probert\", token=True, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"ibm/probert\", token=True, trust_remote_code=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Entities and Pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Any library can be used to extract the entities and pronouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_corenlp_url = 'https://corenlp.run/'\n",
    "corenlp = StanfordCoreNLP(_corenlp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = [\"Pat (they/them/their) was not sure how they should bring up inclusivity in the workplace.\",\n",
    "                 \"Pat was not sure how he should bring up inclusivity in the workplace.\"\n",
    "                ] \n",
    "# original_text = [\n",
    "#                     \"Kathleen Nott was born in Camberwell, London. Her father, Philip, was a lithographic printer, and her mother, Ellen, ran a boarding house in Brixton; Kathleen was their third daughter. \\\n",
    "#                         She was educated at Mary Datchelor Girls' School (now closed), London, before attending King's College, London. This is where she met and married them.\",\n",
    "#                     \"Lamogha (they/them/their) was not sure how she should bring up inclusivity in the workplace.\",\n",
    "#                     \"Lamogha (she/her) was not sure how she should bring up inclusivity in the workplace.\"\n",
    "#                 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Pat': [0]}, {'Pat': [0]}] [{'they': [5, 39], 'them': [10], 'their': [15]}, {'he': [21]}]\n"
     ]
    }
   ],
   "source": [
    "def is_pronoun(sentence, entity):\n",
    "    for token_dict in sentence['tokens']:\n",
    "        if token_dict['originalText'] == entity:\n",
    "            return token_dict['pos'] == 'PRP' or token_dict['pos'] == 'PRP$'\n",
    "\n",
    "# need to get combinations of every pronoun + offset with every entity + offset\n",
    "def get_combinations(entity_dict, pronoun_dict):\n",
    "    combinations = []\n",
    "    # each pronoun\n",
    "    for pronoun in pronoun_dict:\n",
    "        # offset for each pronoun\n",
    "        for pronoun_offset in pronoun_dict[pronoun]:\n",
    "            finished_entities = []\n",
    "            # each pair of entities\n",
    "            for entity1 in entity_dict:\n",
    "                # no duplicates (only want one of [[entity1 = a], [entity2 = b]])\n",
    "                if entity1 not in finished_entities:\n",
    "                    # offset for each entity\n",
    "                    for entity1_offset in entity_dict[entity1]:\n",
    "                        combinations.append([pronoun, pronoun_offset, entity1, entity1_offset])\n",
    "                finished_entities.append(entity1)\n",
    "            \n",
    "    return combinations\n",
    "\n",
    "def get_entities_and_pronouns(original_text: List[str]):\n",
    "    entity_list, pronoun_list = [], []\n",
    "    if type(original_text) != list and original_text != []:\n",
    "        raise Exception(\"Input must be a list of strings.\")\n",
    "    \n",
    "    for i in range(len(original_text)):\n",
    "        entity_dict, pronoun_dict = {}, {}\n",
    "        root = json.loads(corenlp.annotate(original_text[i], properties={'annotators': 'parse,coref,openie,ner', \"timeout\": \"50000\"}))\n",
    "\n",
    "        for sentence_idx in range(len(root['sentences'])):\n",
    "            sentence = root['sentences'][sentence_idx]\n",
    "            for idx in range(len(sentence['entitymentions'])):\n",
    "                entity = sentence['entitymentions'][idx]['ner']\n",
    "                text = sentence['entitymentions'][idx]['text']\n",
    "                if entity == 'PERSON' and not is_pronoun(sentence, text):\n",
    "                    entity_dict[text] = []\n",
    "            for token_dict in sentence['tokens']:\n",
    "                if token_dict['pos'] == 'PRP' or token_dict['pos'] == 'PRP$':\n",
    "                    pronoun_dict[token_dict['originalText']] = []\n",
    "        # add offset from ORIGINAL text \n",
    "        # (can't add directly from above because coref annotation adds spaces / other chars) \n",
    "        for name in entity_dict:\n",
    "            if entity_dict[name] == []:\n",
    "                entity_dict[name] = [word.start() for word in re.finditer(name, original_text[i])]\n",
    "        for name in pronoun_dict:\n",
    "            if pronoun_dict[name] == []:\n",
    "                regex=re.compile(rf\"\\b{name}\\b\")\n",
    "                pronoun_dict[name] = [word.start() for word in regex.finditer(original_text[i])]\n",
    "        \n",
    "        entity_list.append(entity_dict)\n",
    "        pronoun_list.append(pronoun_dict)\n",
    "    return entity_list, pronoun_list\n",
    "\n",
    "entity_list, pronoun_list = get_entities_and_pronouns(original_text)\n",
    "print(entity_list, pronoun_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data by annotating with new mention and pronoun tags.\n",
    "def annotate_mentions(ex):\n",
    "        ex.a_offset = int(ex.a_offset)\n",
    "        ex.pronoun_offset = int(ex.pronoun_offset)\n",
    "        text = ex.text\n",
    "        \n",
    "        text = '{}<A> {}'.format(text[:ex.a_offset], text[ex.a_offset:])\n",
    "        offset = ex.pronoun_offset\n",
    "        if ex.pronoun_offset > ex.a_offset:\n",
    "            offset += 4\n",
    "            \n",
    "        text = '{}<P> {}'.format(text[:offset], text[offset:])\n",
    "        ex.a_offset = text.index('<A> ') + 4\n",
    "        ex.pronoun_offset = text.index('<P> ') + 4\n",
    "        offset = 5*len(re.findall('<(C|D|E)_.>', re.search(''.join([re.escape(c)+'(<(C|D|E)_.>)*?' for c in ex.a]), text[ex.a_offset:])[0]))\n",
    "        text = '{} <A>{}'.format(text[:ex.a_offset+len(ex.a)+offset], text[ex.a_offset+len(ex.a)+offset:])\n",
    "        \n",
    "        offset = 0\n",
    "        if ex.pronoun_offset > ex.a_offset:\n",
    "            offset += 4\n",
    "        offset += 5*len(re.findall('<(C|D|E)_.>', text[ex.pronoun_offset:ex.pronoun_offset+len(ex.pronoun)]))\n",
    "        text = '{} <P>{}'.format(text[:ex.pronoun_offset+len(ex.pronoun)+offset], \n",
    "                                    text[ex.pronoun_offset+len(ex.pronoun)+offset:])\n",
    "\n",
    "        ex.text = text \n",
    "        return text\n",
    "\n",
    "\n",
    "def transform(X, pretrained=None):\n",
    "    # X = pd.read_csv(X, sep='\\t')\n",
    "    X = X.copy()\n",
    "    X['text'] = X.progress_apply(annotate_mentions, axis=1)\n",
    "    pretrained = pd.DataFrame(np.ones((len(X), 2))*0.33)\n",
    "    y = pd.DataFrame([[False]]*len(X), columns=['A'])\n",
    "    y['NEITHER'] = ~y['A']\n",
    "    if 'a_coref' in X.columns:\n",
    "        y = pd.DataFrame(X[['a_coref']].values, columns=['A'])\n",
    "        y['NEITHER'] = ~y['A']\n",
    "            \n",
    "    X['label'] = np.argmax(y.values, axis=1)\n",
    "    X['pretrained'] = pretrained.values.tolist()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Convert to Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, \n",
    "                                    tokenizer,\n",
    "                                    max_seq_length,\n",
    "                                    n_coref_models,\n",
    "                                    max_gpr_mention_len=20,\n",
    "                                    pad_value=0,\n",
    "                                    verbose=0):\n",
    "\n",
    "    features = []\n",
    "    for ex_index, example in tqdm(examples.iterrows(), \n",
    "                                    desc='Convert Examples to features', \n",
    "                                    disable=False):\n",
    "\n",
    "        tokens = tokenizer.tokenize(example.text)\n",
    "\n",
    "        if get_sanitized_seq_len(tokens)[0] > max_seq_length - 2:\n",
    "            tokens = _truncate_seq(tokens, max_seq_length - 2)\n",
    "\n",
    "        tokens_ = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "\n",
    "        # first set with gpr tags\n",
    "        tokens, _, _, _ = extract_cluster_ids(ex_index,\n",
    "                                           tokens_.copy(),\n",
    "                                           n_coref_models,\n",
    "                                           max_mention_len=8,\n",
    "                                           remove_gpr_tags=False)\n",
    "\n",
    "        # second without gpr tags only to be used for coref clusters embeddings\n",
    "        _, cluster_ids_a, cluster_ids_b, cluster_ids_p = extract_cluster_ids(ex_index, \n",
    "                                                                            tokens_.copy(), \n",
    "                                                                            n_coref_models, \n",
    "                                                                            max_mention_len=8,\n",
    "                                                                            remove_gpr_tags=True)\n",
    "        \n",
    "        # mention_ids = A, B and P entity token indices\n",
    "        # gpr_tag_ids = <A>, <B>, <P> tag token indices\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. \n",
    "        mention_p_ids, mention_a_ids, mention_b_ids, gpr_tag_ids = get_gpr_mention_ids(tokens, \n",
    "                                                                                        max_gpr_mention_len,\n",
    "                                                                                        ignore_gpr_tags=True)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        gpr_tags_mask = np.zeros(len(tokens))\n",
    "        gpr_tags_mask[gpr_tag_ids] = 1\n",
    "        gpr_tags_mask = gpr_tags_mask.tolist()\n",
    "        mention_p_mask = [1] * len(mention_p_ids)\n",
    "        mention_a_mask = [1] * len(mention_a_ids)\n",
    "\n",
    "        # Zero-pad up to the max sequence length.\n",
    "        padding = [pad_value] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        gpr_tags_mask += padding\n",
    "        mention_p_ids += [pad_value] * (max_gpr_mention_len - len(mention_p_ids))\n",
    "        mention_a_ids += [pad_value] * (max_gpr_mention_len - len(mention_a_ids))\n",
    "        mention_p_mask += [pad_value] * (max_gpr_mention_len - len(mention_p_mask))\n",
    "        mention_a_mask += [pad_value] * (max_gpr_mention_len - len(mention_a_mask))\n",
    "\n",
    "        # Zero pad coref clusters\n",
    "        cluster_ids_a, cluster_mask_a = pad_cluster_ids(cluster_ids_a, n_coref_models, \n",
    "                                                        max_seq_length,\n",
    "                                                        max_mention_len=8,\n",
    "                                                        max_coref_mentions=20,\n",
    "                                                        pad_value=pad_value)\n",
    "        cluster_ids_p, cluster_mask_p = pad_cluster_ids(cluster_ids_p, n_coref_models, \n",
    "                                                        max_seq_length,\n",
    "                                                        max_mention_len=8,\n",
    "                                                        max_coref_mentions=20,\n",
    "                                                        pad_value=pad_value)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(tokens) <= max_seq_length, '{}\\n{}\\n{}'.format(ex_index, len(tokens), tokens)\n",
    "        assert ''.join(tokens).upper().count('<P>') == 2 and ''.join(tokens).upper().count('<A>') == 2, (ex_index,\n",
    "        \"\".join(tokens).upper().count('<P>'), \"\".join(tokens).upper().count('<A>'),\"\".join(tokens))\n",
    "\n",
    "        features.append(\n",
    "                AttrDict({'input_ids': input_ids,\n",
    "                              'input_mask': input_mask,\n",
    "                              'segment_ids': segment_ids,\n",
    "                              'gpr_tags_mask': gpr_tags_mask,\n",
    "                              'mention_p_ids': mention_p_ids,\n",
    "                              'mention_a_ids': mention_a_ids,\n",
    "                              'mention_p_mask': mention_p_mask,\n",
    "                              'mention_a_mask': mention_a_mask,\n",
    "                              'cluster_ids_a': cluster_ids_a,\n",
    "                              'cluster_mask_a': cluster_mask_a,\n",
    "                              'cluster_ids_p': cluster_ids_p,\n",
    "                              'cluster_mask_p': cluster_mask_p,\n",
    "                              'label_id': example.label,\n",
    "                              'pretrained': example.pretrained}))\n",
    "    return features\n",
    "\n",
    "def get_gpr_mention_ids(tokens, max_gpr_mention_len, ignore_gpr_tags=False):\n",
    "    gpr_ids = {'<P>': [], '<A>': [], '<B>': []}\n",
    "    gpr_tag_ids = []\n",
    "    entity = None\n",
    "    for i, token_ in enumerate(tokens):\n",
    "        token = ''.join(tokens[i:i+3]).upper()\n",
    "\n",
    "        if token in ['<P>', '<A>', '<B>']:\n",
    "            gpr_tag_ids += [i, i+1, i+2]\n",
    "            gpr_tag_ids_now = [i, i+1, i+2]\n",
    "\n",
    "        if entity is not None and token not in ['<P>', '<A>', '<B>']:\n",
    "            if ignore_gpr_tags:\n",
    "                gpr_ids[entity].append(i+2-len(gpr_tag_ids_now))\n",
    "            else:\n",
    "                gpr_ids[entity].append(i+2)\n",
    "\n",
    "        if token in ['<P>', '<A>', '<B>']:\n",
    "            if entity == token:\n",
    "                entity = None\n",
    "            else:\n",
    "                entity = token\n",
    "    # This is only returning 1 mention id for <P> and 2 for <A>. Think there's a bug here.\n",
    "    return (gpr_ids['<P>'][:][:max_gpr_mention_len], \n",
    "            # gpr_ids['<P>'][:-2][:max_gpr_mention_len], \n",
    "            gpr_ids['<A>'][:-2][:max_gpr_mention_len], \n",
    "            gpr_ids['<B>'][:-2][:max_gpr_mention_len], \n",
    "            gpr_tag_ids)\n",
    "\n",
    "def pad_cluster_ids(cluster_ids, n_coref_models, max_seq_length, \n",
    "                    max_mention_len=4, \n",
    "                    max_coref_mentions=5,\n",
    "                    pad_value=0):\n",
    "    # pad cluster ids\n",
    "    cluster_mask = [[] for i in range(n_coref_models)]\n",
    "\n",
    "    for model_idx in range(n_coref_models):\n",
    "        # limit to 10 mentions max for now\n",
    "        # pad mentions length\n",
    "        model_cluster_ids = cluster_ids[model_idx][:max_coref_mentions]\n",
    "        for i, mention in enumerate(model_cluster_ids):\n",
    "            cluster_mask[model_idx].append([1] * len(model_cluster_ids[i]) + [0] * (max_mention_len-len(model_cluster_ids[i])))\n",
    "            model_cluster_ids[i] += [pad_value] * (max_mention_len-len(model_cluster_ids[i]))\n",
    "        cluster_ids[model_idx] = model_cluster_ids\n",
    "\n",
    "        # pad cluster lengths\n",
    "        if len(cluster_ids[model_idx]) < max_coref_mentions:\n",
    "            cluster_ids[model_idx] += [[pad_value] * max_mention_len] * (max_coref_mentions-len(cluster_ids[model_idx]))\n",
    "            cluster_mask[model_idx] += [[0] * max_mention_len] * (max_coref_mentions-len(cluster_mask[model_idx]))\n",
    "\n",
    "    return cluster_ids, cluster_mask\n",
    "\n",
    "def populate_cluster(cluster_ids, tokens_to_remove, token_ids):\n",
    "    if len(cluster_ids[-1]) == 0:\n",
    "        tokens_to_remove += token_ids\n",
    "        cluster_ids[-1].append(token_ids[-1] + 1 - len(tokens_to_remove))\n",
    "    else:\n",
    "        mention_tokens = range(cluster_ids[-1][0], token_ids[0] - len(tokens_to_remove))\n",
    "        mention_tokens = list(mention_tokens)\n",
    "        cluster_ids.pop()\n",
    "        cluster_ids.append(mention_tokens)\n",
    "        tokens_to_remove += token_ids\n",
    "        cluster_ids.append([])\n",
    "\n",
    "    return cluster_ids, tokens_to_remove\n",
    "\n",
    "def filter_coref_mentions(tokens, cluster_ids, max_mention_len=4):\n",
    "    mentions = []\n",
    "    for mention in cluster_ids:\n",
    "        if len(mention) == 0:\n",
    "            print(cluster_ids, tokens, mention)\n",
    "        token_ids = []\n",
    "        start = mention[0]\n",
    "        while start < mention[-1]+1:\n",
    "            token = ''.join(tokens[start:start+3]).upper()\n",
    "            if token in ['<P>', '<A>', '<B>']:\n",
    "                start += 2\n",
    "            else:\n",
    "                token_ids.append(start)\n",
    "\n",
    "            start += 1\n",
    "\n",
    "        if len(token_ids) <= max_mention_len:\n",
    "            mentions.append(token_ids)\n",
    "\n",
    "    return mentions\n",
    "\n",
    "def extract_cluster_ids(ex_index, tokens, n_coref_models, max_mention_len=4, remove_gpr_tags=False):\n",
    "    gpr_tags = ['<P>', '<A>', '<B>']\n",
    "    if remove_gpr_tags:\n",
    "        tokens_ = []\n",
    "        start = 0\n",
    "        while start < len(tokens):\n",
    "            if ''.join(tokens[start:start+3]).upper() in gpr_tags:\n",
    "                start += 3\n",
    "            else:\n",
    "                tokens_.append(tokens[start])\n",
    "                start += 1\n",
    "        tokens = tokens_\n",
    "\n",
    "    cluster_tags = ['<C_{}>'.format(i) for i in range(n_coref_models)] + \\\n",
    "                        ['<D_{}>'.format(i) for i in range(n_coref_models)] + \\\n",
    "                        ['<E_{}>'.format(i) for i in range(n_coref_models)]\n",
    "\n",
    "    # map cluster ids to tokens so that we can make pairs and keep track of token ids for removal\n",
    "    map_idx_to_token = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        token = ''.join(tokens[start:start+5]).upper()\n",
    "\n",
    "        if token in cluster_tags:\n",
    "            mapping = (list(range(start, start+5)), token)\n",
    "            map_idx_to_token.append(mapping)\n",
    "        else:\n",
    "            map_idx_to_token.append(([start], tokens[start]))\n",
    "        start += 1\n",
    "\n",
    "    cluster_ids_a = [[[]] for i in range(n_coref_models)]\n",
    "    cluster_ids_b = [[[]] for i in range(n_coref_models)]\n",
    "    cluster_ids_p = [[[]] for i in range(n_coref_models)]\n",
    "    tokens_to_remove = []\n",
    "    for (token_ids, token) in map_idx_to_token:\n",
    "        if token in cluster_tags:\n",
    "            coref_model_idx = int(token[3])\n",
    "            if 'C' in token:\n",
    "                cluster_ids_a[coref_model_idx], tokens_to_remove = populate_cluster(cluster_ids_a[coref_model_idx], \n",
    "                                                                                    tokens_to_remove, \n",
    "                                                                                    token_ids)\n",
    "            if 'D' in token:\n",
    "                cluster_ids_b[coref_model_idx], tokens_to_remove = populate_cluster(cluster_ids_b[coref_model_idx], \n",
    "                                                                                    tokens_to_remove, \n",
    "                                                                                    token_ids)\n",
    "            if 'E' in token:\n",
    "                cluster_ids_p[coref_model_idx], tokens_to_remove = populate_cluster(cluster_ids_p[coref_model_idx], \n",
    "                                                                                    tokens_to_remove, \n",
    "                                                                                    token_ids)\n",
    "\n",
    "    for i in range(n_coref_models):\n",
    "        cluster_ids_a[i].pop()\n",
    "        cluster_ids_b[i].pop()\n",
    "        cluster_ids_p[i].pop()\n",
    "\n",
    "    # remove coref tags from tokens\n",
    "    for i, idx in enumerate(tokens_to_remove):\n",
    "        del tokens[idx-i]\n",
    "\n",
    "    # gather tokens between cluster tags\n",
    "    # filter out coref mention that are either a gpr tag or has tokens more than 6\n",
    "    for i in range(n_coref_models):\n",
    "        cluster_ids_a[i] = filter_coref_mentions(tokens, cluster_ids_a[i], max_mention_len=max_mention_len)\n",
    "        cluster_ids_b[i] = filter_coref_mentions(tokens, cluster_ids_b[i], max_mention_len=max_mention_len)\n",
    "        cluster_ids_p[i] = filter_coref_mentions(tokens, cluster_ids_p[i], max_mention_len=max_mention_len)\n",
    "\n",
    "    return tokens, cluster_ids_a, cluster_ids_b, cluster_ids_p\n",
    "\n",
    "def remove_first_matching_tag(tokens, tag):\n",
    "    start = 1\n",
    "    while start < len(tokens):\n",
    "        if ''.join(tokens[start:start+5]) == tag:\n",
    "            del tokens[start:start+5]\n",
    "            break\n",
    "        start += 1\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def get_sanitized_seq_len(tokens):\n",
    "    seq_len = 0\n",
    "    start = 0\n",
    "    tokens_ = []\n",
    "    while start < len(tokens):\n",
    "        if (''.join(tokens[start:start+3] + tokens[start+4:start+5])).upper() in ['<C_>', '<D_>', '<E_>']:\n",
    "            start += 5\n",
    "        else:\n",
    "            tokens_.append(tokens[start])\n",
    "            seq_len += 1\n",
    "            start += 1\n",
    "\n",
    "    return seq_len, tokens_\n",
    "\n",
    "def _truncate_seq(tokens, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # 1. First truncate the begining\n",
    "    # 2. truncate the end\n",
    "    # 3. truncate the middle\n",
    "\n",
    "    # map gpr tokens - cannot be removed\n",
    "    # if a token matches c or d, then don't consider it in sequence length\n",
    "    \n",
    "    gpr_tags = ['<P>', '<A>', '<B>']\n",
    "    cluster_tags = ['<C_>', '<D_>', '<E_>']\n",
    "    # 1 Start truncating from begining\n",
    "    #   if first token is not in gpr tags then remove it.\n",
    "    #       if it was a cluster tag, then remove the corresponding matching end tag as well\n",
    "    while get_sanitized_seq_len(tokens)[0] > max_length:\n",
    "        _, sanitized_tokens = get_sanitized_seq_len(tokens)\n",
    "\n",
    "        token = ''.join(sanitized_tokens[0:3]).upper()\n",
    "        if token not in gpr_tags:\n",
    "            # while first token is a cluster tag keep removing it and its matching end tag\n",
    "            while (''.join(tokens[:3] + tokens[4:5])).upper() in ['<C_>', '<D_>', '<E_>']:\n",
    "                tokens = remove_first_matching_tag(tokens, ''.join(tokens[:5]))\n",
    "                del tokens[:5]\n",
    "            del tokens[0]\n",
    "            continue\n",
    "\n",
    "        token = ''.join(sanitized_tokens[-3:]).upper()\n",
    "        if token not in gpr_tags:\n",
    "            # while last token is a cluster tag keep removing it and its matching start tag\n",
    "            while (''.join(tokens[-5:-2] + tokens[-1:])).upper() in ['<C_>', '<D_>', '<E_>']:\n",
    "                tokens_ = tokens[::-1]\n",
    "                tokens = remove_first_matching_tag(tokens_, ''.join(tokens_[:5]))\n",
    "                tokens = tokens[::-1]\n",
    "                del tokens[-5:]\n",
    "            del tokens[-1]\n",
    "            continue\n",
    "\n",
    "        raise Exception('Couldnt find a good way to truncate the sequence.')\n",
    "\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Prediction Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X,device,eval_mode=True):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in X], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in X], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in X], dtype=torch.long)\n",
    "    all_gpr_tags_mask = torch.tensor([f.gpr_tags_mask for f in X], dtype=torch.uint8)\n",
    "\n",
    "    all_mention_p_ids = torch.tensor([f.mention_p_ids for f in X], dtype=torch.long)\n",
    "    all_mention_a_ids = torch.tensor([f.mention_a_ids for f in X], dtype=torch.long)\n",
    "    all_mention_p_mask = torch.tensor([f.mention_p_mask for f in X], dtype=torch.uint8)\n",
    "    all_mention_a_mask = torch.tensor([f.mention_a_mask for f in X], dtype=torch.uint8)\n",
    "\n",
    "    all_cluster_ids_a = torch.tensor([f.cluster_ids_a for f in X], dtype=torch.long)\n",
    "    all_cluster_mask_a = torch.tensor([f.cluster_mask_a for f in X], dtype=torch.uint8)\n",
    "    all_cluster_ids_p = torch.tensor([f.cluster_ids_p for f in X], dtype=torch.long)\n",
    "    all_cluster_mask_p = torch.tensor([f.cluster_mask_p for f in X], dtype=torch.uint8)\n",
    "\n",
    "    all_pretrained = torch.tensor([f.pretrained for f in X], dtype=torch.float)\n",
    "    \n",
    "    all_label_ids = torch.tensor([f.label_id for f in X], dtype=torch.long)\n",
    "\n",
    "    eval_data = TensorDataset(all_input_ids, \n",
    "                                all_input_mask, \n",
    "                                all_segment_ids, \n",
    "                                all_gpr_tags_mask,\n",
    "                                all_mention_p_ids,\n",
    "                                all_mention_a_ids,\n",
    "                                all_mention_p_mask,\n",
    "                                all_mention_a_mask,\n",
    "                                all_cluster_ids_a,\n",
    "                                all_cluster_mask_a,\n",
    "                                all_cluster_ids_p,\n",
    "                                all_cluster_mask_p,\n",
    "                                all_pretrained,\n",
    "                                all_label_ids)\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, \n",
    "                                sampler=eval_sampler, \n",
    "                                batch_size=1)\n",
    "\n",
    "    eval_loss = 0\n",
    "    preds = []\n",
    "    attn_wts = []\n",
    "    pbar = tqdm(desc=\"Evaluating\", total=len(eval_dataloader)) if eval_mode else contextlib.suppress()\n",
    "    with pbar:\n",
    "        for step, batch in enumerate(eval_dataloader):\n",
    "            # with torch.cuda.device(0):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            (input_ids, input_mask, segment_ids, \n",
    "                gpr_tags_mask,\n",
    "                mention_p_ids, mention_a_ids,\n",
    "                mention_p_mask, mention_a_mask,\n",
    "                cluster_ids_a, cluster_mask_a,\n",
    "                cluster_ids_p, cluster_mask_p, pretrained, label_ids) = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                res = model(input_ids,\n",
    "                            segment_ids, \n",
    "                            input_mask, \n",
    "                            gpr_tags_mask=gpr_tags_mask,\n",
    "                            mention_p_ids=mention_p_ids,\n",
    "                            mention_a_ids=mention_a_ids,\n",
    "                            mention_p_mask=mention_p_mask,\n",
    "                            mention_a_mask=mention_a_mask, \n",
    "                            cluster_ids_a=cluster_ids_a,\n",
    "                            cluster_mask_a=cluster_mask_a,\n",
    "                            cluster_ids_p=cluster_ids_p,\n",
    "                            cluster_mask_p=cluster_mask_p,\n",
    "                            pretrained=pretrained,\n",
    "                            labels=None,\n",
    "                            training=False,\n",
    "                            eval_mode=eval_mode\n",
    "                        )\n",
    "\n",
    "                if eval_mode:\n",
    "                    logits, probabilties, attn_wts_m, attn_wts_c, attn_wts_co = res\n",
    "                else:\n",
    "                    logits, probabilties = res\n",
    "\n",
    "            if len(preds) == 0:\n",
    "                preds.append(probabilties.detach().cpu().numpy())\n",
    "            else:\n",
    "                preds[0] = np.append(preds[0], probabilties.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "            if eval_mode:\n",
    "                pbar.update()\n",
    "\n",
    "                if len(attn_wts) == 0:\n",
    "                    attn_wts = [attn_wts_m, attn_wts_c]\n",
    "                else:\n",
    "                    attn_wts[0] = np.append(attn_wts[0], attn_wts_m, axis=0)\n",
    "                    attn_wts[1] = np.append(attn_wts[1], attn_wts_c, axis=0)\n",
    "\n",
    "    preds = preds[0]\n",
    "    return preds, attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>pronoun_offset</th>\n",
       "      <th>a</th>\n",
       "      <th>a_offset</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>they</td>\n",
       "      <td>5</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>they</td>\n",
       "      <td>39</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>them</td>\n",
       "      <td>10</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>their</td>\n",
       "      <td>15</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat was not sure how he should bring up inclus...</td>\n",
       "      <td>he</td>\n",
       "      <td>21</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text pronoun  \\\n",
       "0  na  Pat (they/them/their) was not sure how they sh...    they   \n",
       "1  na  Pat (they/them/their) was not sure how they sh...    they   \n",
       "2  na  Pat (they/them/their) was not sure how they sh...    them   \n",
       "3  na  Pat (they/them/their) was not sure how they sh...   their   \n",
       "4  na  Pat was not sure how he should bring up inclus...      he   \n",
       "\n",
       "   pronoun_offset    a  a_offset url  \n",
       "0               5  Pat         0  na  \n",
       "1              39  Pat         0  na  \n",
       "2              10  Pat         0  na  \n",
       "3              15  Pat         0  na  \n",
       "4              21  Pat         0  na  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1740.38it/s]\n",
      "Convert Examples to features: 5it [00:00, 1213.14it/s]\n",
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]/u/lamogha/.cache/huggingface/modules/transformers_modules/ibm/probert/1f84cb7bc4cdb88bdbf4e1b3b55f1df15209331a/probert.py:66: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1680572619157/work/aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  sequence_output = sequence_output[~gpr_tags_mask].view(batch_size, -1, self.config.hidden_size)\n",
      "Evaluating: 100%|██████████| 5/5 [00:08<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialize results data frame\n",
    "from pickle import FALSE, TRUE\n",
    "\n",
    "cols = ['id', 'text', 'pronoun', 'pronoun_offset', 'a', 'a_offset', 'url']\n",
    "\n",
    "output_cols = ['id', 'text', 'pronoun', 'pronoun_offset', 'a', 'a_offset', 'a_coref', 'url', 'probabilities', 'output']\n",
    "df_list = []\n",
    "\n",
    "for i in range(len(original_text)):\n",
    "    combinations = get_combinations(entity_list[i], pronoun_list[i])\n",
    "    for combination in combinations:\n",
    "        pronoun, pronoun_offset = combination[0], combination[1]\n",
    "        entity1, entity1_offset = combination[2], combination[3]\n",
    "        \n",
    "        df_list.append(['na',original_text[i], pronoun,pronoun_offset,entity1,entity1_offset,'na'])\n",
    "\n",
    "df = pd.DataFrame(df_list, columns=cols)\n",
    "         \n",
    "tmp_write_path = 'tmp_df.csv'\n",
    "df.to_csv(tmp_write_path, sep='\\t', index=False)\n",
    "display(df)\n",
    "X_annotated = transform(df)\n",
    "# Tokenisation of the text happens here\n",
    "X = convert_examples_to_features(X_annotated,tokenizer,512,n_coref_models=0,verbose=0)\n",
    "\n",
    "# inference using model\n",
    "labels = [True,False]\n",
    "predicted_probs, _ = predict(model,X,device,eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known pronoun 'they' resolves 'True' to 'Pat' with a probability of '0.9717698693275452'\n",
      "Known pronoun 'they' resolves 'True' to 'Pat' with a probability of '0.6899465918540955'\n",
      "Known pronoun 'them' resolves 'True' to 'Pat' with a probability of '0.8984460830688477'\n",
      "Known pronoun 'their' resolves 'True' to 'Pat' with a probability of '0.612221896648407'\n",
      "Known pronoun 'he' resolves 'True' to 'Pat' with a probability of '0.994134247303009'\n"
     ]
    }
   ],
   "source": [
    "# index of max value from predictions so we get exact entity name it resolves to\n",
    "output_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    pronoun = row['pronoun']\n",
    "    pronoun_offset = row['pronoun_offset']\n",
    "    entity1 = row['a']\n",
    "    entity1_offset = row['a_offset']\n",
    "    text = row['text']\n",
    "    probs = predicted_probs[idx]\n",
    "\n",
    "    max_idx = list(probs).index(max(probs))\n",
    "    \n",
    "    output = f\"Known pronoun '{pronoun}' resolves '{labels[max_idx]}' to '{entity1}' with a probability of '{probs[max_idx]}'\"\n",
    "    print(output)\n",
    "    entity_coref = labels[max_idx]\n",
    "    output_list.append(['na',text, pronoun,pronoun_offset,entity1,entity1_offset,entity_coref,'na', probs, output])\n",
    "\n",
    "# new_df_output = pd.DataFrame([], columns=output_cols)\n",
    "# df_output = pd.concat([df_output, new_df_output])\n",
    "df_output = pd.DataFrame(output_list, columns=output_cols)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>pronoun_offset</th>\n",
       "      <th>a</th>\n",
       "      <th>a_offset</th>\n",
       "      <th>a_coref</th>\n",
       "      <th>url</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>they</td>\n",
       "      <td>5</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>[0.97176987 0.02823015]</td>\n",
       "      <td>Known pronoun 'they' resolves 'True' to 'Pat' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>they</td>\n",
       "      <td>39</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>[0.6899466  0.31005344]</td>\n",
       "      <td>Known pronoun 'they' resolves 'True' to 'Pat' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>them</td>\n",
       "      <td>10</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>[0.8984461  0.10155394]</td>\n",
       "      <td>Known pronoun 'them' resolves 'True' to 'Pat' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat (they/them/their) was not sure how they sh...</td>\n",
       "      <td>their</td>\n",
       "      <td>15</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>[0.6122219 0.3877781]</td>\n",
       "      <td>Known pronoun 'their' resolves 'True' to 'Pat'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>Pat was not sure how he should bring up inclus...</td>\n",
       "      <td>he</td>\n",
       "      <td>21</td>\n",
       "      <td>Pat</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>na</td>\n",
       "      <td>[0.99413425 0.00586572]</td>\n",
       "      <td>Known pronoun 'he' resolves 'True' to 'Pat' wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text pronoun  \\\n",
       "0  na  Pat (they/them/their) was not sure how they sh...    they   \n",
       "1  na  Pat (they/them/their) was not sure how they sh...    they   \n",
       "2  na  Pat (they/them/their) was not sure how they sh...    them   \n",
       "3  na  Pat (they/them/their) was not sure how they sh...   their   \n",
       "4  na  Pat was not sure how he should bring up inclus...      he   \n",
       "\n",
       "   pronoun_offset    a  a_offset  a_coref url            probabilities  \\\n",
       "0               5  Pat         0     True  na  [0.97176987 0.02823015]   \n",
       "1              39  Pat         0     True  na  [0.6899466  0.31005344]   \n",
       "2              10  Pat         0     True  na  [0.8984461  0.10155394]   \n",
       "3              15  Pat         0     True  na    [0.6122219 0.3877781]   \n",
       "4              21  Pat         0     True  na  [0.99413425 0.00586572]   \n",
       "\n",
       "                                              output  \n",
       "0  Known pronoun 'they' resolves 'True' to 'Pat' ...  \n",
       "1  Known pronoun 'they' resolves 'True' to 'Pat' ...  \n",
       "2  Known pronoun 'them' resolves 'True' to 'Pat' ...  \n",
       "3  Known pronoun 'their' resolves 'True' to 'Pat'...  \n",
       "4  Known pronoun 'he' resolves 'True' to 'Pat' wi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename_wr = 'df_output_hf.csv'\n",
    "df_output.to_csv(filename_wr, index=False)\n",
    "eval_data_plot = pd.read_csv(filename_wr)\n",
    "display(eval_data_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Run the git gpr_pub clone only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gpr_pub'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 301, done.\u001b[K\n",
      "remote: Total 301 (delta 0), reused 0 (delta 0), pack-reused 301\u001b[K\n",
      "Receiving objects: 100% (301/301), 5.36 MiB | 1.12 MiB/s, done.\n",
      "Resolving deltas: 100% (132/132), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sattree/gpr_pub.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".highlight {\n",
       "  border: 2px solid;\n",
       "  color: #232323;\n",
       "  margin: 4px 6px 4px 3px;\n",
       "  vertical-align: middle;\n",
       "  box-shadow: 2px 4px 20px rgba(0,0,0,0.1);\n",
       "  position: relative;\n",
       "  cursor: default;\n",
       "  min-width: 26px;\n",
       "  line-height: 22px;\n",
       "  display: inline-flex;\n",
       "}\n",
       "\n",
       ".highlight:last-child {\n",
       "  margin-right: 4px;\n",
       "}\n",
       "\n",
       ".highlight:first-child {\n",
       "  margin-left: 0;\n",
       "}\n",
       "\n",
       ".highlight,\n",
       ".highlight span {\n",
       "  transition: background-color .1s ease,\n",
       "              color .1s ease,\n",
       "              box-shadow .1s ease,\n",
       "              opacity .1s ease;\n",
       "}\n",
       "\n",
       ".highlight.short-text {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".highlight__label {\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  padding: 0 8px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "}\n",
       "\n",
       ".highlight__label strong,\n",
       ".highlight__label span.highlight__label__secondary-label {\n",
       "  display: block;\n",
       "  font-size: 11px;\n",
       "  color: #fff;\n",
       "  -webkit-font-smoothing: subpixel-antialiased;\n",
       "  letter-spacing: 0.1em;\n",
       "}\n",
       "\n",
       ".highlight__label strong {\n",
       "  text-transform: uppercase;\n",
       "}\n",
       "\n",
       ".highlight__label span.highlight__label__secondary-label {\n",
       "  opacity: .75;\n",
       "  padding-left: 6px;\n",
       "}\n",
       "\n",
       ".highlight__content {\n",
       "  flex-wrap: wrap;\n",
       "  align-items: center;\n",
       "  padding: 2px 2px 2px 6px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight-container.highlight-container--bottom-labels .highlight.bottom {\n",
       "  margin-top: 6px;\n",
       "}\n",
       "\n",
       ".highlight.bottom {\n",
       "  display: block;\n",
       "  white-space: normal;\n",
       "}\n",
       "\n",
       ".highlight.bottom .highlight__content:after {\n",
       "  content: \" \";\n",
       "  padding-right: 3px;\n",
       "}\n",
       "\n",
       ".highlight.bottom .highlight__label {\n",
       "  line-height: 14px;\n",
       "  padding-top: 1px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.top {\n",
       "  flex-direction: column;\n",
       "  white-space: normal;\n",
       "}\n",
       "\n",
       ".highlight.top .highlight__label {\n",
       "  min-height: 22px;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.active,\n",
       ".highlight.active span {\n",
       "  color: #fff;\n",
       "}\n",
       "\n",
       ".highlight.active .highlight:not(.active) span {\n",
       "  color: #232323;\n",
       "}\n",
       "\n",
       ".highlight.clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight.clickable.clickable.selected {\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       ".highlight.clickable.clicking {\n",
       "  opacity: 0.66;\n",
       "  transition-duration: 0s;\n",
       "}\n",
       "\n",
       ".clicking .highlight,\n",
       ".clicking .highlight span,\n",
       ".clicking .highlight:before,\n",
       ".clicking .highlight:after {\n",
       "  transition-duration: 0s;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.gray {\n",
       "  background: #f2f4f6;\n",
       "}\n",
       "\n",
       ".highlight.gray,\n",
       ".highlight-arrow--gray .highlight-arrow__triangle {\n",
       "  border-color: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray .highlight__label,\n",
       ".highlight-arrow--gray .highlight-arrow__stalk,\n",
       ".highlight.gray .highlight__button .highlight__button__body {\n",
       "  background-color: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray.active {\n",
       "  background: #a0aab5;\n",
       "}\n",
       "\n",
       ".highlight.gray.active .highlight__label {\n",
       "  background-color: #aab3bd;\n",
       "}\n",
       "\n",
       ".highlight.gray .highlight__button svg {\n",
       "  fill: #a0aab5;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".highlight.blue {\n",
       "  background: #edf4fa;\n",
       "}\n",
       "\n",
       ".highlight.blue,\n",
       ".highlight-arrow--blue .highlight-arrow__triangle {\n",
       "  border-color: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue > .highlight__label,\n",
       ".highlight-arrow--blue .highlight-arrow__stalk,\n",
       ".highlight.blue .highlight__button .highlight__button__body {\n",
       "  background-color: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue.active {\n",
       "  background: #4db1f7;\n",
       "}\n",
       "\n",
       ".highlight.blue.active > .highlight__label {\n",
       "  background-color: #5fb9f8;\n",
       "}\n",
       "\n",
       ".highlight.blue .highlight__button svg {\n",
       "  fill: #4db1f7;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.green {\n",
       "  background: #f1f4f1;\n",
       "}\n",
       "\n",
       ".highlight.green,\n",
       ".highlight-arrow--green .highlight-arrow__triangle {\n",
       "  border-color: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green > .highlight__label,\n",
       ".highlight-arrow--green .highlight-arrow__stalk,\n",
       ".highlight.green .highlight__button .highlight__button__body {\n",
       "  background-color: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green.active {\n",
       "  background: #90ac4e;\n",
       "}\n",
       "\n",
       ".highlight.green.active > .highlight__label {\n",
       "  background-color: #9bb460;\n",
       "}\n",
       "\n",
       ".highlight.green .highlight__button svg {\n",
       "  fill: #90ac4e;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.pink {\n",
       "  background: #f4f1f4;\n",
       "}\n",
       "\n",
       ".highlight.pink,\n",
       ".highlight-arrow--pink .highlight-arrow__triangle {\n",
       "  border-color: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink > .highlight__label,\n",
       ".highlight-arrow--pink .highlight-arrow__stalk,\n",
       ".highlight.pink .highlight__button .highlight__button__body {\n",
       "  background-color: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink.active {\n",
       "  background: #ce6587;\n",
       "}\n",
       "\n",
       ".highlight.pink.active > .highlight__label {\n",
       "  background-color: #d37593;\n",
       "}\n",
       "\n",
       ".highlight.pink .highlight__button svg {\n",
       "  fill: #ce6587;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.orange {\n",
       "  background: #f2f4f4;\n",
       "}\n",
       "\n",
       ".highlight.orange,\n",
       ".highlight-arrow--orange .highlight-arrow__triangle {\n",
       "  border-color: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange > .highlight__label,\n",
       ".highlight-arrow--orange .highlight-arrow__stalk,\n",
       ".highlight.orange .highlight__button .highlight__button__body {\n",
       "  background-color: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange.active {\n",
       "  background: #dd9e3e;\n",
       "}\n",
       "\n",
       ".highlight.orange.active > .highlight__label {\n",
       "  background-color: #e0a852;\n",
       "}\n",
       "\n",
       ".highlight.orange .highlight__button svg {\n",
       "  fill: #dd9e3e;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.purple {\n",
       "  background: #f1f0f7;\n",
       "}\n",
       "\n",
       ".highlight.purple,\n",
       ".highlight-arrow--purple .highlight-arrow__triangle {\n",
       "  border-color: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple > .highlight__label,\n",
       ".highlight-arrow--purple .highlight-arrow__stalk,\n",
       ".highlight.purple .highlight__button .highlight__button__body {\n",
       "  background-color: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple.active {\n",
       "  background: #9a5eba;\n",
       "}\n",
       "\n",
       ".highlight.purple.active > .highlight__label {\n",
       "  background-color: #a46ec1;\n",
       "}\n",
       "\n",
       ".highlight.purple .highlight__button svg {\n",
       "  fill: #9a5eba;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.teal {\n",
       "  background: #eef4f6;\n",
       "}\n",
       "\n",
       ".highlight.teal,\n",
       ".highlight-arrow--teal .highlight-arrow__triangle {\n",
       "  border-color: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal > .highlight__label,\n",
       ".highlight-arrow--teal .highlight-arrow__stalk,\n",
       ".highlight.teal .highlight__button .highlight__button__body {\n",
       "  background-color: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal.active {\n",
       "  background: #5bb1ad;\n",
       "}\n",
       "\n",
       ".highlight.teal.active > .highlight__label {\n",
       "  background-color: #6cb9b5;\n",
       "}\n",
       "\n",
       ".highlight.teal .highlight__button svg {\n",
       "  fill: #5bb1ad;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.tan {\n",
       "  background: #f2f4f4;\n",
       "}\n",
       "\n",
       ".highlight.tan,\n",
       ".highlight-arrow--tan .highlight-arrow__triangle {\n",
       "  border-color: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan > .highlight__label,\n",
       ".highlight-arrow--tan .highlight-arrow__stalk,\n",
       ".highlight.tan .highlight__button .highlight__button__body {\n",
       "  background-color: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan.active {\n",
       "  background: #b0a481;\n",
       "}\n",
       "\n",
       ".highlight.tan.active > .highlight__label {\n",
       "  background-color: #b8ad8e;\n",
       "}\n",
       "\n",
       ".highlight.tan .highlight__button svg {\n",
       "  fill: #b0a481;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.red {\n",
       "  background: #f5eef0;\n",
       "}\n",
       "\n",
       ".highlight.red,\n",
       ".highlight-arrow--red .highlight-arrow__triangle {\n",
       "  border-color: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red > .highlight__label,\n",
       ".highlight-arrow--red .highlight-arrow__stalk,\n",
       ".highlight.red .highlight__button .highlight__button__body {\n",
       "  background-color: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red.active {\n",
       "  background: #df3838;\n",
       "}\n",
       "\n",
       ".highlight.red.active > .highlight__label {\n",
       "  background-color: #e24c4c;\n",
       "}\n",
       "\n",
       ".highlight.red .highlight__button svg {\n",
       "  fill: #df3838;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.cobalt {\n",
       "  background: #eef0f5;\n",
       "}\n",
       "\n",
       ".highlight.cobalt,\n",
       ".highlight-arrow--cobalt .highlight-arrow__triangle {\n",
       "  border-color: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt > .highlight__label,\n",
       ".highlight-arrow--cobalt .highlight-arrow__stalk,\n",
       ".highlight.cobalt .highlight__button .highlight__button__body {\n",
       "  background-color: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt.active {\n",
       "  background: #5f5b97;\n",
       "}\n",
       "\n",
       ".highlight.cobalt.active > .highlight__label {\n",
       "  background-color: #6f6ca2;\n",
       "}\n",
       "\n",
       ".highlight.cobalt .highlight__button svg {\n",
       "  fill: #5f5b97;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.brown {\n",
       "  background: #f2f4f6;\n",
       "}\n",
       "\n",
       ".highlight.brown,\n",
       ".highlight-arrow--brown .highlight-arrow__triangle {\n",
       "  border-color: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown > .highlight__label,\n",
       ".highlight-arrow--brown .highlight-arrow__stalk,\n",
       ".highlight.brown .highlight__button .highlight__button__body {\n",
       "  background-color: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown.active {\n",
       "  background: #6a4e3d;\n",
       "}\n",
       "\n",
       ".highlight.brown.active > .highlight__label {\n",
       "  background-color: #796051;\n",
       "}\n",
       "\n",
       ".highlight.brown .highlight__button svg {\n",
       "  fill: #6a4e3d;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight.slate {\n",
       "  background: #eceff1;\n",
       "}\n",
       "\n",
       ".highlight.slate,\n",
       ".highlight-arrow--slate .highlight-arrow__triangle {\n",
       "  border-color: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate > .highlight__label,\n",
       ".highlight-arrow--slate .highlight-arrow__stalk,\n",
       ".highlight.slate .highlight__button .highlight__button__body {\n",
       "  background-color: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate.active {\n",
       "  background: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.slate.active > .highlight__label {\n",
       "  background-color: #4f555a;\n",
       "}\n",
       "\n",
       ".highlight.slate .highlight__button svg {\n",
       "  fill: #3b4247;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia {\n",
       "  background: #f5f1f9;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia,\n",
       ".highlight-arrow--fuchsia .highlight-arrow__triangle {\n",
       "  border-color: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia > .highlight__label,\n",
       ".highlight-arrow--fuchsia .highlight-arrow__stalk,\n",
       ".highlight.fuchsia .highlight__button .highlight__button__body {\n",
       "  background-color: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia.active {\n",
       "  background: #e875e8;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia.active > .highlight__label {\n",
       "  background-color: #ea83ea;\n",
       "}\n",
       "\n",
       ".highlight.fuchsia .highlight__button svg {\n",
       "  fill: #e875e8;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight__tooltip {\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  box-shadow: 0 0 30px rgba(0,0,0,.2);\n",
       "  border-radius: 6px;\n",
       "  background: rgba(70,70,70,.9);\n",
       "  padding: 4px 9px 5px 9px;\n",
       "  opacity: 0;\n",
       "  z-index: -9;\n",
       "  left: 50%;\n",
       "  top: 100%;\n",
       "  margin-top: 10px;\n",
       "  font-size: 14px;\n",
       "  color: #fff;\n",
       "  transform: translate(-50%, -6px);\n",
       "  transition: opacity .2s ease,\n",
       "              z-index .2s ease,\n",
       "              transform .2s ease .3s;\n",
       "  font-weight: bold;\n",
       "  white-space: nowrap;\n",
       "  user-select: none;\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       ".highlight__tooltip:before {\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  left: 50%;\n",
       "  top: 0;\n",
       "  margin-top: -6px;\n",
       "  margin-left: -6px;\n",
       "  content: \"\";\n",
       "  width: 0;\n",
       "  height: 0;\n",
       "  border-style: solid;\n",
       "  border-width: 0 6px 6px 6px;\n",
       "  border-color: transparent transparent rgba(70,70,70,.9) transparent;\n",
       "}\n",
       "\n",
       ".highlight:hover .highlight__tooltip {\n",
       "  z-index: 9;\n",
       "  opacity: 1;\n",
       "  transform: translate(-50%, 0);\n",
       "  transition-delay: 0s;\n",
       "}\n",
       "\n",
       ".highlight__tooltip:hover {\n",
       "  z-index: -9 !important;\n",
       "}\n",
       "\n",
       ".highlight-container {\n",
       "  line-height: 42px !important;\n",
       "  align-items: center;\n",
       "  display: flex;\n",
       "  flex-wrap: wrap;\n",
       "  white-space: pre;\n",
       "  cursor: default;\n",
       "}\n",
       "\n",
       "\n",
       ".highlight-container.highlight-container--bottom-labels {\n",
       "  padding: 10px 1.125em;\n",
       "  align-items: flex-start;\n",
       "}\n",
       "\n",
       ".highlight-container.highlight-container--diagram {\n",
       "  align-items: flex-start;\n",
       "}\n",
       "\n",
       ".highlight-container.highlight-container--diagram.passage.model__content__summary {\n",
       "  background: transparent;\n",
       "  align-items: stretch;\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    \n",
       "function handleHighlightMouseOver(el) {\n",
       "    $('[id='+el.getAttribute('id')+']').addClass('active');\n",
       "  }\n",
       "\n",
       "function handleHighlightMouseOut(el) {\n",
       "    $('[id='+el.getAttribute('id')+']').removeClass('active');\n",
       "}\n",
       "  \n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from gpr_pub import visualization\n",
    "\n",
    "# Add css styles and js events to DOM, so that they are available to rendered html\n",
    "display(HTML(open('gpr_pub/visualization/highlight.css').read()))\n",
    "display(HTML(open('gpr_pub/visualization/highlight.js').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelled_pronoun(row):\n",
    "    txt = row.text\n",
    "\n",
    "    # map char indices to token indices\n",
    "    tokens = txt.split(' ')\n",
    "    start_a = len(txt[:row.a_offset].split(' '))-1\n",
    "\n",
    "    clusters = [[[start_a, start_a+len(row.a.split(' '))-1]]]\n",
    "\n",
    "    # add pronoun token to the labelled cluster\n",
    "    start_p = len(txt[:row.pronoun_offset].split(' '))-1\n",
    "    if row.a_coref:\n",
    "        clusters[0].append([start_p, start_p+len(row.pronoun.split(' '))-1])\n",
    "    else:\n",
    "        clusters.append([[start_p, start_p+len(row.pronoun.split(' '))-1]])\n",
    "\n",
    "    return tokens, clusters\n",
    "\n",
    "def to_html(tokens, clusters):\n",
    "    tree = visualization.html_template.transform_to_tree(tokens, clusters)\n",
    "    html = ''.join(visualization.html_template.span_wrapper(tree, 0))\n",
    "    html = '<div style=\"padding: 16px;\">{}</div>'.format(html)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cda62_row0_col0, #T_cda62_row0_col1, #T_cda62_row1_col0, #T_cda62_row1_col1, #T_cda62_row2_col0, #T_cda62_row2_col1, #T_cda62_row3_col0, #T_cda62_row3_col1, #T_cda62_row4_col0, #T_cda62_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cda62\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cda62_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_cda62_level0_col1\" class=\"col_heading level0 col1\" >annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >sample_idx</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cda62_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cda62_row0_col0\" class=\"data row0 col0\" >Pat (they/them/their) was not sure how they should bring up inclusivity in the workplace.</td>\n",
       "      <td id=\"T_cda62_row0_col1\" class=\"data row0 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span key=1 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>(they/them/their) </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span>they </span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cda62_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cda62_row1_col0\" class=\"data row1 col0\" >Pat (they/them/their) was not sure how they should bring up inclusivity in the workplace.</td>\n",
       "      <td id=\"T_cda62_row1_col1\" class=\"data row1 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>(they/them/their) </span><span>was </span><span>not </span><span>sure </span><span>how </span><span key=6 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>they </span></span></span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cda62_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cda62_row2_col0\" class=\"data row2 col0\" >Pat (they/them/their) was not sure how they should bring up inclusivity in the workplace.</td>\n",
       "      <td id=\"T_cda62_row2_col1\" class=\"data row2 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span key=1 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>(they/them/their) </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span>they </span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cda62_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cda62_row3_col0\" class=\"data row3 col0\" >Pat (they/them/their) was not sure how they should bring up inclusivity in the workplace.</td>\n",
       "      <td id=\"T_cda62_row3_col1\" class=\"data row3 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span key=1 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>(they/them/their) </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span>they </span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace. </span></div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cda62_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_cda62_row4_col0\" class=\"data row4 col0\" >Pat was not sure how he should bring up inclusivity in the workplace.</td>\n",
       "      <td id=\"T_cda62_row4_col1\" class=\"data row4 col1\" ><div style=\"padding: 16px;\"><span key=0 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>Pat </span></span></span><span>was </span><span>not </span><span>sure </span><span>how </span><span key=5 class=\"highlight blue\" depth=0 id=0 onmouseover=\"handleHighlightMouseOver(this)\"                 onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">                <span class=\"highlight__label\"><strong>0</strong></span>                <span class=\"highlight__content\"><span>he </span></span></span><span>should </span><span>bring </span><span>up </span><span>inclusivity </span><span>in </span><span>the </span><span>workplace. </span></div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# row = eval_data_plot.loc[len(eval_data_plot)-1]\n",
    "rows = []\n",
    "for idx, row in eval_data_plot.iterrows():\n",
    "    # Special rendering for labelled pronouns\n",
    "    # labels in 'a_coref'\n",
    "    tokens, clusters = labelled_pronoun(row)\n",
    "    html = to_html(tokens, clusters)\n",
    "    rows.append({'sample_idx': idx,\n",
    "                 'text': row.text,\n",
    "                 'annotation': html})\n",
    "\n",
    "df = pd.DataFrame(rows).groupby(['sample_idx']).agg(lambda x: x)\n",
    "s = df.style.set_properties(**{'text-align': 'left'})\n",
    "display(HTML(s.to_html(justify='left')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Clean up after\n",
    "!rm -rf gpr_pub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/dccstor/t4jmedia4374/miniconda3/envs/mandrel/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_tags(df):\n",
    "    # ex = []\n",
    "    ex = {\"text\":[], \"value\": []}\n",
    "    for idx, row in df.iterrows():\n",
    "        txt = ' '.join(' '.join(row.text.strip().split(\" \")).split())\n",
    "        start_a = len(txt[:row.a_offset].split(' '))-1\n",
    "        start_p = len(txt[:row.pronoun_offset].split(' '))-1\n",
    "        if not txt in ex[\"text\"]:\n",
    "            ex[\"text\"].append(txt)\n",
    "            ex_val_dict = {\"words\": [], \"arcs\": []}\n",
    "            tokens = txt.split()\n",
    "            for i,t in enumerate(tokens):\n",
    "                if t.strip() != '' and t.strip() in row.a:\n",
    "                    ex_val_dict[\"words\"].append({\"text\": t, \"tag\": \"entity\"})\n",
    "                    if start_a < start_p:\n",
    "                        arc = {\"start\": start_a, \"end\": start_p, \"label\": row.a_coref, \"dir\":\"left\"}\n",
    "                    else:\n",
    "                        arc = {\"start\": start_a, \"end\": start_p, \"label\": row.a_coref, \"dir\":\"right\"}\n",
    "                    if not arc in ex_val_dict[\"arcs\"]:\n",
    "                        ex_val_dict[\"arcs\"].append(arc)      \n",
    "                else:\n",
    "                    ex_val_dict[\"words\"].append({\"text\": t, \"tag\": f\"token_{i}\"})   \n",
    "            ex[\"value\"].append(ex_val_dict)\n",
    "        else:\n",
    "            text_idx = ex[\"text\"].index(txt)\n",
    "            arc = {\"start\": start_a, \"end\": start_p, \"label\": row.a_coref, \"dir\":\"left\"}\n",
    "            if not arc in ex[\"value\"][text_idx][\"arcs\"]:\n",
    "                ex[\"value\"][text_idx][\"arcs\"].append(arc)      \n",
    "    return ex[\"value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0365ea8bdfd54baface9ec6980d68f2e-0\" class=\"displacy\" width=\"2500\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Pat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">entity</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">(they/them/their)</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">token_1</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">token_2</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">token_3</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">sure</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">token_4</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">how</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">token_5</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">they</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">token_6</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">should</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">token_7</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">bring</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">token_8</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">up</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">token_9</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">inclusivity</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">token_10</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">token_11</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">token_12</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">workplace.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">token_13</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0365ea8bdfd54baface9ec6980d68f2e-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0365ea8bdfd54baface9ec6980d68f2e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">True</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0365ea8bdfd54baface9ec6980d68f2e-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0365ea8bdfd54baface9ec6980d68f2e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">True</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0365ea8bdfd54baface9ec6980d68f2e-1\" class=\"displacy\" width=\"2325\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Pat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">entity</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">token_1</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">token_2</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sure</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">token_3</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">how</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">token_4</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">he</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">token_5</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">should</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">token_6</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">bring</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">token_7</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">up</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">token_8</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">inclusivity</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">token_9</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">token_10</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">token_11</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">workplace.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">token_12</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0365ea8bdfd54baface9ec6980d68f2e-1-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 925.0,2.0 925.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0365ea8bdfd54baface9ec6980d68f2e-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">True</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ex_to_use = ex_tags(eval_data_plot)\n",
    "html = displacy.render(ex_to_use, style=\"dep\", manual=True, jupyter=True)\n",
    "display(HTML(html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
